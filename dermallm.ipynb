{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cOgX1p82Q-sVOt2KEuMkW9EpEGDnFurW",
      "authorship_tag": "ABX9TyMcUd45L9o41oEevPF8xvd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emmanuel10701/AI-skin-llm-model/blob/main/dermallm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jjA9H-3U-VfB",
        "outputId": "83307a43-2eed-4b64-a49f-3690a5d9fc59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒŸ ENHANCED AI Skin Disease Analysis System ğŸŒŸ\n",
            "This tool provides preliminary analysis but is NOT a substitute for professional medical advice.\n",
            "Always consult healthcare providers for proper diagnosis and treatment.\n",
            "\n",
            "ğŸ¤– Welcome to the Enhanced Skin Disease Analysis System!\n",
            "==================================================\n",
            "ğŸŒŸ Features:\n",
            "   â€¢ AI-powered image analysis\n",
            "   â€¢ Custom SQLite database integration\n",
            "   â€¢ Conversational memory\n",
            "   â€¢ Real-time skin condition matching\n",
            "==================================================\n",
            "Choose AI model:\n",
            "1. Gemini (Recommended for images)\n",
            "2. GPT-4 (Not implemented yet)\n",
            "Choice (1/2): 1\n",
            "Enter your Google Gemini API key: AIzaSyCR8xhkE6XNCdgmgRJFtKyodhsMz5jfbQE\n",
            "âœ… Gemini API key set successfully!\n",
            "\n",
            "Options:\n",
            "1. Upload skin image for analysis\n",
            "2. View analysis history\n",
            "3. Query skin disease database\n",
            "4. Clear history\n",
            "5. Quit\n",
            "\n",
            "Choose an option (1-5): 3\n",
            "Enter your question about skin conditions: e actinic keratosis (rough, scaly patches), precancerous lesions like Bowen disease, many unusual or irregular moles (dysplastic nevi), and skin that is very fair, burns easily, or has a history of severe sunburns\n",
            "\n",
            "ğŸ¤– Database Response: Could not find relevant information.\n",
            "\n",
            "Options:\n",
            "1. Upload skin image for analysis\n",
            "2. View analysis history\n",
            "3. Query skin disease database\n",
            "4. Clear history\n",
            "5. Quit\n",
            "\n",
            "Choose an option (1-5): 3\n",
            "Enter your question about skin conditions:  \"thick red patches (plaques)\",             \"silvery or white scales\",             \"dry, cracked, or bleeding skin\",             \"itching, burning, or soreness\",             \"pitted or ridged nails\",\n",
            "\n",
            "ğŸ¤– Database Response: Could not find relevant information.\n",
            "\n",
            "Options:\n",
            "1. Upload skin image for analysis\n",
            "2. View analysis history\n",
            "3. Query skin disease database\n",
            "4. Clear history\n",
            "5. Quit\n",
            "\n",
            "Choose an option (1-5): 1\n",
            "ğŸ“· Please upload a clear image of the skin condition\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aaaeccce-346d-4c53-9f2d-408eab37790f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aaaeccce-346d-4c53-9f2d-408eab37790f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1024px-Rosacea_01-1-599da39b685fbe001018a5b2.jpg to 1024px-Rosacea_01-1-599da39b685fbe001018a5b2.jpg\n",
            "\n",
            "ğŸ” Analyzing skin condition (ID: skin_analysis_1_233417)...\n",
            "============================================================\n",
            "ğŸ” Analyzing skin image...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 10248.64ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error analyzing image: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "ğŸ” Extracting symptoms...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error extracting symptoms: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "ğŸ” Querying skin disease database...\n",
            "ğŸ” Diagnosing possible conditions...\n",
            "âœ… Possible conditions: []\n",
            "âœ… Confidence: 0.00\n",
            "ğŸš¨ Emergency: False\n",
            "ğŸ” Generating recommendations...\n",
            "âœ… Recommendations generated: 3 actions\n",
            "ğŸ’¬ Initiating AI conversation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âŒ Error initiating conversation: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š ENHANCED SKIN ANALYSIS RESULTS:\n",
            "============================================================\n",
            "ğŸ©º Symptoms Identified: \n",
            "ğŸ¨ Skin Tone: Unknown\n",
            "ğŸ“ Affected Area: Unknown\n",
            "âš ï¸  Severity Level: Unknown\n",
            "ğŸ” Possible Conditions: \n",
            "ğŸ“ˆ Confidence Score: 0.00\n",
            "ğŸ’¾ Database Insights: No symptoms available for database query.\n",
            "\n",
            "ğŸ’¡ RECOMMENDED ACTIONS:\n",
            "   1. Keep the affected area clean and dry\n",
            "   2. Avoid scratching or irritating the area\n",
            "   3. Monitor for changes in size, color, or symptoms\n",
            "\n",
            "ğŸ’¬ AI Assistant is ready to answer your questions!\n",
            "You can ask about:\n",
            "â€¢ Specific skin conditions\n",
            "â€¢ Treatment options\n",
            "â€¢ Symptom explanations\n",
            "â€¢ Prevention tips\n",
            "â€¢ Type 'quit' to return to main menu\n",
            "\n",
            "ğŸ’­ Your question: give methedetail you got instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2122845340.py\", line 817, in follow_up_conversation\n",
            "    response = llm.invoke(enhanced_prompt)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
            "    self.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\", line 961, in _generate\n",
            "    response: GenerateContentResponse = _chat_with_retry(\n",
            "                                        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\", line 196, in _chat_with_retry\n",
            "    return _chat_with_retry(**kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\", line 194, in _chat_with_retry\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\", line 178, in _chat_with_retry\n",
            "    return generation_method(**kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 835, in generate_content\n",
            "    response = rpc(\n",
            "               ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
            "    return wrapped_func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\", line 294, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\", line 156, in retry_target\n",
            "    next_sleep = _retry_error_helper(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\", line 214, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\", line 147, in retry_target\n",
            "    result = target()\n",
            "             ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\", line 130, in func_with_timeout\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\", line 78, in error_remapped_callable\n",
            "    raise exceptions.from_grpc_error(exc) from exc\n",
            "google.api_core.exceptions.NotFound: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ Error generating response: 404 models/gemini-1.5-flash-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -qU langchain-google-genai langchain PyPDF2 python-docx requests langgraph pillow google-generativeai streamlit sqlalchemy\n",
        "\n",
        "# Import required modules\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from typing import TypedDict, List, Optional, Any, Dict\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langgraph.graph import StateGraph, END\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import io\n",
        "import requests\n",
        "import re\n",
        "import sqlite3\n",
        "# from llama_index.core import VectorStoreIndex, Document, StorageContext\n",
        "# from llama_index.vector_stores import InMemoryVectorStore\n",
        "# from llama_index.memory import ChatMemoryBuffer\n",
        "\n",
        "# --- 1. Set up API Keys and Models ---\n",
        "class APIKeyManager:\n",
        "    def __init__(self):\n",
        "        self.gemini_key = None\n",
        "        self.gpt_key = None\n",
        "\n",
        "    def set_gemini_key(self, key):\n",
        "        self.gemini_key = key\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = key\n",
        "        genai.configure(api_key=key)\n",
        "\n",
        "    def set_gpt_key(self, key):\n",
        "        self.gpt_key = key\n",
        "\n",
        "api_manager = APIKeyManager()\n",
        "\n",
        "# --- 2. Define the State for our Graph ---\n",
        "class SkinAnalysisState(TypedDict):\n",
        "    \"\"\"Represents the state of the skin disease analysis process.\"\"\"\n",
        "    image_data: str  # Base64 encoded image\n",
        "    image_description: str\n",
        "    symptoms: List[str]\n",
        "    skin_tone: str\n",
        "    affected_area: str\n",
        "    severity_level: str  # Mild, Moderate, Severe\n",
        "    possible_conditions: List[str]\n",
        "    confidence_score: float\n",
        "    recommended_actions: List[str]\n",
        "    emergency_flag: bool\n",
        "    conversation_history: List[Dict[str, str]]\n",
        "    user_api_key: str\n",
        "    timestamp: str\n",
        "    current_query: str\n",
        "    database_context: str\n",
        "    # memory_context: str\n",
        "\n",
        "# --- 3. Enhanced Database with SQLite Integration ---\n",
        "class SkinDiseaseDatabase:\n",
        "    def __init__(self, db_name=\"skin_diseases.db\"):\n",
        "        self.db_name = db_name\n",
        "        self._initialize_database()\n",
        "\n",
        "    def _initialize_database(self):\n",
        "        \"\"\"Initialize the SQLite database and create tables.\"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Create conditions table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS conditions (\n",
        "                name TEXT PRIMARY KEY,\n",
        "                description TEXT,\n",
        "                emergency BOOLEAN\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create symptoms table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS symptoms (\n",
        "                condition_name TEXT,\n",
        "                symptom TEXT,\n",
        "                FOREIGN KEY (condition_name) REFERENCES conditions(name)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create severity levels table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS severity_levels (\n",
        "                condition_name TEXT,\n",
        "                level TEXT,\n",
        "                recommendation TEXT,\n",
        "                FOREIGN KEY (condition_name) REFERENCES conditions(name)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        self.populate_database()\n",
        "\n",
        "    def populate_database(self):\n",
        "        \"\"\"Populate the database with initial skin disease data.\"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Example data (can be expanded)\n",
        "        initial_data = {\n",
        "            \"acne\": {\n",
        "                \"description\": \"A common skin condition that occurs when hair follicles become clogged with oil and dead skin cells.\",\n",
        "                \"symptoms\": [\"pimples\", \"blackheads\", \"whiteheads\", \"redness\", \"inflammation\"],\n",
        "                \"severity_levels\": {\n",
        "                    \"mild\": [\"topical treatments\", \"cleansing\"],\n",
        "                    \"moderate\": [\"prescription creams\", \"oral antibiotics\"],\n",
        "                    \"severe\": [\"dermatologist referral\", \"isotretinoin\"]\n",
        "                },\n",
        "                \"emergency\": False,\n",
        "            },\n",
        "            \"eczema\": {\n",
        "                \"description\": \"A condition that makes skin red and itchy, common in children but can occur at any age.\",\n",
        "                \"symptoms\": [\"dry skin\", \"itching\", \"redness\", \"cracks\", \"scaling\"],\n",
        "                \"severity_levels\": {\n",
        "                    \"mild\": [\"moisturizers\", \"avoid triggers\"],\n",
        "                    \"moderate\": [\"topical steroids\", \"antihistamines\"],\n",
        "                    \"severe\": [\"dermatologist referral\", \"phototherapy\"]\n",
        "                },\n",
        "                \"emergency\": False,\n",
        "            },\n",
        "            \"psoriasis\": {\n",
        "                \"description\": \"A skin disorder that causes skin cells to multiply up to 10 times faster than normal.\",\n",
        "                \"symptoms\": [\"thick red patches\", \"silvery scales\", \"dryness\", \"itching\"],\n",
        "                \"severity_levels\": {\n",
        "                    \"mild\": [\"moisturizers\", \"topical treatments\"],\n",
        "                    \"moderate\": [\"light therapy\", \"vitamin D analogs\"],\n",
        "                    \"severe\": [\"biologics\", \"systemic medications\"]\n",
        "                },\n",
        "                \"emergency\": False,\n",
        "            },\n",
        "             \"skin_cancer\": {\n",
        "                \"description\": \"Abnormal growth of skin cells, most often develops on skin exposed to the sun.\",\n",
        "                \"symptoms\": [\"asymmetrical mole\", \"irregular borders\", \"color changes\", \"growing lesion\"],\n",
        "                \"severity_levels\": {\n",
        "                    \"mild\": [\"urgent dermatologist visit\"],\n",
        "                    \"moderate\": [\"immediate medical attention\"],\n",
        "                    \"severe\": [\"emergency care required\"]\n",
        "                },\n",
        "                \"emergency\": True,\n",
        "            },\n",
        "            \"cellulitis\": {\n",
        "                \"description\": \"A common bacterial skin infection that can become serious if not treated promptly.\",\n",
        "                \"symptoms\": [\"redness spreading\", \"swelling\", \"pain\", \"fever\", \"warmth\"],\n",
        "                \"severity_levels\": {\n",
        "                    \"mild\": [\"urgent care visit\"],\n",
        "                    \"moderate\": [\"emergency room\"],\n",
        "                    \"severe\": [\"immediate hospitalization\"]\n",
        "                },\n",
        "                \"emergency\": True,\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for condition, info in initial_data.items():\n",
        "            cursor.execute(\"INSERT OR IGNORE INTO conditions VALUES (?, ?, ?)\",\n",
        "                           (condition, info.get(\"description\"), info.get(\"emergency\", False)))\n",
        "\n",
        "            for symptom in info.get(\"symptoms\", []):\n",
        "                cursor.execute(\"INSERT OR IGNORE INTO symptoms VALUES (?, ?)\", (condition, symptom))\n",
        "\n",
        "            for level, recommendations in info.get(\"severity_levels\", {}).items():\n",
        "                for recommendation in recommendations:\n",
        "                     cursor.execute(\"INSERT OR IGNORE INTO severity_levels VALUES (?, ?, ?)\", (condition, level, recommendation))\n",
        "\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "    def get_condition_info(self, condition_name):\n",
        "        \"\"\"Retrieve detailed information for a specific condition.\"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM conditions WHERE name = ?\", (condition_name.lower(),))\n",
        "        condition_row = cursor.fetchone()\n",
        "        conn.close()\n",
        "\n",
        "        if condition_row:\n",
        "            condition_info = {\n",
        "                \"name\": condition_row[0],\n",
        "                \"description\": condition_row[1],\n",
        "                \"emergency\": bool(condition_row[2]),\n",
        "                \"symptoms\": self.get_symptoms_for_condition(condition_row[0]),\n",
        "                \"severity_levels\": self.get_severity_levels_for_condition(condition_row[0])\n",
        "            }\n",
        "            return condition_info\n",
        "        return {}\n",
        "\n",
        "    def get_symptoms_for_condition(self, condition_name):\n",
        "        \"\"\"Retrieve symptoms for a specific condition.\"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT symptom FROM symptoms WHERE condition_name = ?\", (condition_name.lower(),))\n",
        "        symptoms = [row[0] for row in cursor.fetchall()]\n",
        "        conn.close()\n",
        "        return symptoms\n",
        "\n",
        "    def get_severity_levels_for_condition(self, condition_name):\n",
        "        \"\"\"Retrieve severity levels and recommendations for a specific condition.\"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT level, recommendation FROM severity_levels WHERE condition_name = ?\", (condition_name.lower(),))\n",
        "        severity_data = {}\n",
        "        for level, recommendation in cursor.fetchall():\n",
        "            if level not in severity_data:\n",
        "                severity_data[level] = []\n",
        "            severity_data[level].append(recommendation)\n",
        "        conn.close()\n",
        "        return severity_data\n",
        "\n",
        "    def find_conditions_by_symptoms(self, symptoms: List[str]) -> List[str]:\n",
        "        \"\"\"Find potential conditions based on a list of symptoms.\"\"\"\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        cursor = conn.cursor()\n",
        "        matching_conditions = set()\n",
        "        for symptom in symptoms:\n",
        "            cursor.execute(\"\"\"\n",
        "                SELECT DISTINCT condition_name FROM symptoms\n",
        "                WHERE symptom LIKE ?\n",
        "            \"\"\", (f\"%{symptom.lower()}%\",))\n",
        "            for row in cursor.fetchall():\n",
        "                matching_conditions.add(row[0])\n",
        "        conn.close()\n",
        "        return list(matching_conditions)\n",
        "\n",
        "    def query_database(self, query: str) -> str:\n",
        "        \"\"\"Process natural language queries against the database (basic).\"\"\"\n",
        "        # This is a very basic implementation. For more complex queries,\n",
        "        # you would need a more sophisticated natural language processing layer.\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        conn = sqlite3.connect(self.db_name)\n",
        "        cursor = conn.cursor()\n",
        "        response = \"Could not find relevant information.\"\n",
        "\n",
        "        # Example basic query handling\n",
        "        if \"symptoms of\" in query_lower:\n",
        "            match = re.search(r\"symptoms of (.*)\", query_lower)\n",
        "            if match:\n",
        "                condition_name = match.group(1).strip()\n",
        "                symptoms = self.get_symptoms_for_condition(condition_name)\n",
        "                if symptoms:\n",
        "                    response = f\"Symptoms of {condition_name.capitalize()}: {', '.join(symptoms)}\"\n",
        "                else:\n",
        "                    response = f\"Could not find symptoms for {condition_name.capitalize()}.\"\n",
        "\n",
        "        elif \"what is\" in query_lower or \"describe\" in query_lower:\n",
        "            match = re.search(r\"(what is|describe) (.*)\", query_lower)\n",
        "            if match:\n",
        "                condition_name = match.group(2).strip()\n",
        "                info = self.get_condition_info(condition_name)\n",
        "                if info:\n",
        "                    response = f\"{condition_name.capitalize()}: {info.get('description', 'No description available.')}\"\n",
        "                else:\n",
        "                    response = f\"Could not find information for {condition_name.capitalize()}.\"\n",
        "\n",
        "        # Add more query patterns as needed\n",
        "\n",
        "        conn.close()\n",
        "        return response\n",
        "\n",
        "\n",
        "# Initialize database\n",
        "skin_db = SkinDiseaseDatabase()\n",
        "\n",
        "# --- 4. Conversation Memory (Using simple list for now) ---\n",
        "class SimpleMemoryManager:\n",
        "    def __init__(self):\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def add_interaction(self, user_message: str, ai_response: str):\n",
        "        \"\"\"Add interaction to memory\"\"\"\n",
        "        interaction = {\n",
        "            \"user\": user_message,\n",
        "            \"ai\": ai_response,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        self.conversation_history.append(interaction)\n",
        "\n",
        "    def get_conversation_context(self, current_query: str = \"\") -> str:\n",
        "        \"\"\"Get recent conversation context\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            return \"No previous conversation history.\"\n",
        "\n",
        "        # Get recent conversations (last 5 exchanges)\n",
        "        recent_conversations = self.conversation_history[-5:]\n",
        "        context = \"Recent conversation history:\\n\"\n",
        "\n",
        "        for i, conv in enumerate(recent_conversations, 1):\n",
        "            context += f\"{i}. User: {conv['user']}\\n   AI: {conv['ai']}\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "    def clear_memory(self):\n",
        "        \"\"\"Clear conversation memory\"\"\"\n",
        "        self.conversation_history = []\n",
        "\n",
        "# Initialize memory manager\n",
        "memory_manager = SimpleMemoryManager()\n",
        "\n",
        "\n",
        "# --- 5. Image Processing Functions ---\n",
        "def encode_image_to_base64(image_file):\n",
        "    \"\"\"Convert uploaded image to base64 string\"\"\"\n",
        "    if isinstance(image_file, str):\n",
        "        # If it's a file path\n",
        "        with open(image_file, \"rb\") as img_file:\n",
        "            return base64.b64encode(img_file.read()).decode('utf-8')\n",
        "    else:\n",
        "        # If it's an uploaded file object\n",
        "        return base64.b64encode(image_file.getvalue()).decode('utf-8')\n",
        "\n",
        "def resize_image(image_data, max_size=(512, 512)):\n",
        "    \"\"\"Resize image to reduce processing load\"\"\"\n",
        "    try:\n",
        "        if isinstance(image_data, str):\n",
        "            # Base64 string\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "        else:\n",
        "            # Bytes\n",
        "            image_bytes = image_data\n",
        "\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "        buffered = io.BytesIO()\n",
        "        image.save(buffered, format=\"JPEG\", quality=85)\n",
        "        return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "    except Exception as e:\n",
        "        print(f\"Error resizing image: {e}\")\n",
        "        return image_data\n",
        "\n",
        "# --- 6. Define the Nodes/Functions (Agents) ---\n",
        "def analyze_image_node(state: SkinAnalysisState) -> SkinAnalysisState:\n",
        "    \"\"\"Uses Gemini to analyze the skin image and extract features.\"\"\"\n",
        "    print(\"ğŸ” Analyzing skin image...\")\n",
        "\n",
        "    try:\n",
        "        # Initialize Gemini model\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "        # Prepare image\n",
        "        image_data = base64.b64decode(state['image_data'])\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "        # Create prompt for image analysis\n",
        "        prompt = \"\"\"\n",
        "        Analyze this skin image carefully and provide a detailed description including:\n",
        "        1. Visible symptoms (redness, swelling, lesions, etc.)\n",
        "        2. Skin tone and texture\n",
        "        3. Affected body area\n",
        "        4. Severity indicators\n",
        "        5. Any concerning features\n",
        "\n",
        "        Be objective and medical in your analysis.\n",
        "        \"\"\"\n",
        "\n",
        "        response = model.generate_content([prompt, image])\n",
        "        state['image_description'] = response.text\n",
        "        print(f\"âœ… Image analysis completed: {state['image_description'][:100]}...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error analyzing image: {e}\")\n",
        "        state['image_description'] = \"Image analysis failed\"\n",
        "\n",
        "    return state\n",
        "\n",
        "def extract_symptoms_node(state: SkinAnalysisState) -> SkinAnalysisState:\n",
        "    \"\"\"Extracts specific symptoms from the image analysis.\"\"\"\n",
        "    print(\"ğŸ” Extracting symptoms...\")\n",
        "\n",
        "    prompt_template = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        Based on the following image analysis, extract specific symptoms and features:\n",
        "\n",
        "        {image_analysis}\n",
        "\n",
        "        Provide a JSON response with:\n",
        "        - symptoms: list of specific symptoms found\n",
        "        - skin_tone: description of skin tone\n",
        "        - affected_area: body area affected\n",
        "        - severity_level: Mild, Moderate, or Severe\n",
        "\n",
        "        Focus on medical accuracy.\n",
        "        \"\"\",\n",
        "        input_variables=[\"image_analysis\"]\n",
        "    )\n",
        "\n",
        "    class SymptomAnalysis(BaseModel):\n",
        "        symptoms: List[str] = Field(description=\"List of specific symptoms observed\")\n",
        "        skin_tone: str = Field(description=\"Description of skin tone\")\n",
        "        affected_area: str = Field(description=\"Body area affected\")\n",
        "        severity_level: str = Field(description=\"Severity level: Mild, Moderate, or Severe\")\n",
        "\n",
        "    try:\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
        "        chain = prompt_template | llm.with_structured_output(SymptomAnalysis)\n",
        "        response = chain.invoke({\"image_analysis\": state['image_description']})\n",
        "\n",
        "        state['symptoms'] = response.symptoms\n",
        "        state['skin_tone'] = response.skin_tone\n",
        "        state['affected_area'] = response.affected_area\n",
        "        state['severity_level'] = response.severity_level\n",
        "\n",
        "        print(f\"âœ… Symptoms extracted: {state['symptoms']}\")\n",
        "        print(f\"âœ… Severity: {state['severity_level']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error extracting symptoms: {e}\")\n",
        "        state['symptoms'] = []\n",
        "        state['skin_tone'] = \"Unknown\"\n",
        "        state['affected_area'] = \"Unknown\"\n",
        "        state['severity_level'] = \"Unknown\"\n",
        "\n",
        "    return state\n",
        "\n",
        "def query_database_node(state: SkinAnalysisState) -> SkinAnalysisState:\n",
        "    \"\"\"Query the skin disease database based on symptoms.\"\"\"\n",
        "    print(\"ğŸ” Querying skin disease database...\")\n",
        "\n",
        "    if not state['symptoms']:\n",
        "        state['database_context'] = \"No symptoms available for database query.\"\n",
        "        return state\n",
        "\n",
        "    # Find conditions based on extracted symptoms\n",
        "    possible_conditions = skin_db.find_conditions_by_symptoms(state['symptoms'])\n",
        "    state['database_context'] = f\"Possible conditions based on symptoms: {', '.join(possible_conditions)}\"\n",
        "    state['possible_conditions'] = possible_conditions # Update possible conditions in state\n",
        "\n",
        "    print(f\"âœ… Database query completed. Possible conditions: {', '.join(possible_conditions)}\")\n",
        "\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def diagnose_conditions_node(state: SkinAnalysisState) -> SkinAnalysisState:\n",
        "    \"\"\"Matches symptoms against medical database to suggest possible conditions.\"\"\"\n",
        "    print(\"ğŸ” Diagnosing possible conditions...\")\n",
        "\n",
        "    user_symptoms = [symptom.lower() for symptom in state['symptoms']]\n",
        "    possible_conditions = []\n",
        "    confidence_scores = []\n",
        "\n",
        "    # Iterate through the database conditions\n",
        "    conn = sqlite3.connect(skin_db.db_name)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT name FROM conditions\")\n",
        "    all_conditions = [row[0] for row in cursor.fetchall()]\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "    for condition_name in all_conditions:\n",
        "        condition_info = skin_db.get_condition_info(condition_name)\n",
        "        condition_symptoms = [s.lower() for s in condition_info.get('symptoms', [])]\n",
        "\n",
        "        # Calculate symptom match score\n",
        "        matched_symptoms = [symptom for symptom in user_symptoms\n",
        "                          if any(symptom in cond_symptom or cond_symptom in symptom\n",
        "                               for cond_symptom in condition_symptoms)]\n",
        "\n",
        "        match_score = len(matched_symptoms) / len(condition_symptoms) if condition_symptoms else 0\n",
        "\n",
        "        if match_score > 0.3:  # Threshold for consideration\n",
        "            possible_conditions.append(condition_name)\n",
        "            confidence_scores.append(match_score)\n",
        "\n",
        "    state['possible_conditions'] = possible_conditions\n",
        "    state['confidence_score'] = max(confidence_scores) if confidence_scores else 0\n",
        "    state['emergency_flag'] = any(skin_db.get_condition_info(cond).get('emergency', False)\n",
        "                                for cond in possible_conditions)\n",
        "\n",
        "    print(f\"âœ… Possible conditions: {state['possible_conditions']}\")\n",
        "    print(f\"âœ… Confidence: {state['confidence_score']:.2f}\")\n",
        "    print(f\"ğŸš¨ Emergency: {state['emergency_flag']}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "def generate_recommendations_node(state: SkinAnalysisState) -> SkinAnalysisState:\n",
        "    \"\"\"Generates personalized recommendations based on diagnosis.\"\"\"\n",
        "    print(\"ğŸ” Generating recommendations...\")\n",
        "\n",
        "    recommendations = []\n",
        "\n",
        "    # Add general recommendations\n",
        "    recommendations.extend([\n",
        "        \"Keep the affected area clean and dry\",\n",
        "        \"Avoid scratching or irritating the area\",\n",
        "        \"Monitor for changes in size, color, or symptoms\"\n",
        "    ])\n",
        "\n",
        "    # Add condition-specific recommendations\n",
        "    for condition in state['possible_conditions']:\n",
        "        condition_info = skin_db.get_condition_info(condition)\n",
        "        severity_recommendations = condition_info.get('severity_levels', {}).get(\n",
        "            state['severity_level'].lower(), []\n",
        "        )\n",
        "        recommendations.extend(severity_recommendations)\n",
        "\n",
        "    # Add emergency recommendations if needed\n",
        "    if state['emergency_flag']:\n",
        "        recommendations.extend([\n",
        "            \"SEEK IMMEDIATE MEDICAL ATTENTION\",\n",
        "            \"Contact healthcare provider immediately\",\n",
        "            \"Do not delay professional medical consultation\"\n",
        "        ])\n",
        "\n",
        "    state['recommended_actions'] = recommendations\n",
        "\n",
        "    print(f\"âœ… Recommendations generated: {len(recommendations)} actions\")\n",
        "\n",
        "    return state\n",
        "\n",
        "def initiate_conversation_node(state: SkinAnalysisState) -> SkinAnalysisState:\n",
        "    \"\"\"Initiates conversation using database context and memory.\"\"\"\n",
        "    print(\"ğŸ’¬ Initiating AI conversation...\")\n",
        "\n",
        "    # Get memory context\n",
        "    memory_context = memory_manager.get_conversation_context()\n",
        "    # state['memory_context'] = memory_context # Removed this as memory_context is not in state\n",
        "\n",
        "    # Create conversation prompt with all available context\n",
        "    conversation_prompt = f\"\"\"\n",
        "    Based on the following skin analysis and conversation history, initiate a helpful conversation with the user:\n",
        "\n",
        "    IMAGE ANALYSIS: {state['image_description']}\n",
        "    SYMPTOMS: {', '.join(state['symptoms'])}\n",
        "    POSSIBLE CONDITIONS: {', '.join(state['possible_conditions'])}\n",
        "    SEVERITY: {state['severity_level']}\n",
        "    DATABASE CONTEXT: {state['database_context']}\n",
        "    CONVERSATION HISTORY:\n",
        "    {memory_context}\n",
        "\n",
        "    Start a natural, empathetic conversation that:\n",
        "    1. Acknowledges the user's concern\n",
        "    2. Summarizes the key findings in simple terms\n",
        "    3. Asks if they have any specific questions\n",
        "    4. Offers to provide more details about the possible conditions\n",
        "\n",
        "    Be professional but friendly and supportive.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
        "        response = llm.invoke(conversation_prompt)\n",
        "\n",
        "        # Store the initial conversation\n",
        "        initial_message = \"Hello! I've analyzed your skin image and I'm here to help you understand the findings.\"\n",
        "        memory_manager.add_interaction(\"User uploaded skin image for analysis\", response.content)\n",
        "\n",
        "        print(f\"âœ… Conversation initiated: {response.content[:100]}...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error initiating conversation: {e}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "# --- 7. Define the Enhanced Graph and Workflow ---\n",
        "workflow = StateGraph(SkinAnalysisState)\n",
        "\n",
        "# Add the nodes to the graph\n",
        "workflow.add_node(\"analyze_image\", analyze_image_node)\n",
        "workflow.add_node(\"extract_symptoms\", extract_symptoms_node)\n",
        "workflow.add_node(\"query_database\", query_database_node)\n",
        "workflow.add_node(\"diagnose_conditions\", diagnose_conditions_node)\n",
        "workflow.add_node(\"generate_recommendations\", generate_recommendations_node)\n",
        "workflow.add_node(\"initiate_conversation\", initiate_conversation_node)\n",
        "\n",
        "\n",
        "# Define the edges (connections)\n",
        "workflow.add_edge(\"analyze_image\", \"extract_symptoms\")\n",
        "workflow.add_edge(\"extract_symptoms\", \"query_database\")\n",
        "workflow.add_edge(\"query_database\", \"diagnose_conditions\")\n",
        "workflow.add_edge(\"diagnose_conditions\", \"generate_recommendations\")\n",
        "workflow.add_edge(\"generate_recommendations\", \"initiate_conversation\")\n",
        "workflow.add_edge(\"initiate_conversation\", END)\n",
        "\n",
        "\n",
        "# Set the entry point of the graph\n",
        "workflow.set_entry_point(\"analyze_image\")\n",
        "\n",
        "# Compile the graph\n",
        "skin_analysis_app = workflow.compile()\n",
        "\n",
        "# --- 8. Enhanced Chat Interface Functions ---\n",
        "def upload_skin_image():\n",
        "    \"\"\"Handles image upload from user\"\"\"\n",
        "    print(\"ğŸ“· Please upload a clear image of the skin condition\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            print(\"âŒ No image uploaded. Please try again.\")\n",
        "            return None\n",
        "\n",
        "        file_name = list(uploaded.keys())[0]\n",
        "        file_content = uploaded[file_name]\n",
        "\n",
        "        # Resize and encode image\n",
        "        resized_image = resize_image(file_content)\n",
        "        return resized_image\n",
        "\n",
        "    except ImportError:\n",
        "        # For non-Colab environments\n",
        "        image_path = input(\"Enter the path to your image file: \")\n",
        "        try:\n",
        "            with open(image_path, \"rb\") as f:\n",
        "                file_content = f.read()\n",
        "            return resize_image(file_content)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error reading image file: {e}\")\n",
        "            return None\n",
        "\n",
        "def initialize_conversation():\n",
        "    \"\"\"Starts a new conversation with API key setup\"\"\"\n",
        "    print(\"ğŸ¤– Welcome to the Enhanced Skin Disease Analysis System!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"ğŸŒŸ Features:\")\n",
        "    print(\"   â€¢ AI-powered image analysis\")\n",
        "    print(\"   â€¢ Custom SQLite database integration\")\n",
        "    print(\"   â€¢ Conversational memory\")\n",
        "    print(\"   â€¢ Real-time skin condition matching\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Get API key from user\n",
        "    api_choice = input(\"Choose AI model:\\n1. Gemini (Recommended for images)\\n2. GPT-4 (Not implemented yet)\\nChoice (1/2): \").strip()\n",
        "\n",
        "    if api_choice == \"1\":\n",
        "        gemini_key = input(\"Enter your Google Gemini API key: \").strip()\n",
        "        if gemini_key:\n",
        "            api_manager.set_gemini_key(gemini_key)\n",
        "            print(\"âœ… Gemini API key set successfully!\")\n",
        "        else:\n",
        "            print(\"âŒ No API key provided. Gemini functionality may be limited.\")\n",
        "    elif api_choice == \"2\":\n",
        "        print(\"GPT-4 integration is not yet implemented.\")\n",
        "        return False # Prevent proceeding if GPT-4 is chosen\n",
        "\n",
        "    return True\n",
        "\n",
        "def chat_interface():\n",
        "    \"\"\"Main chat interface for skin analysis with enhanced features\"\"\"\n",
        "    if not initialize_conversation():\n",
        "        return\n",
        "\n",
        "    conversation_count = 0\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"1. Upload skin image for analysis\")\n",
        "        print(\"2. View analysis history\")\n",
        "        print(\"3. Query skin disease database\")\n",
        "        print(\"4. Clear history\")\n",
        "        print(\"5. Quit\")\n",
        "\n",
        "        choice = input(\"\\nChoose an option (1-5): \").strip()\n",
        "\n",
        "        if choice == '5':\n",
        "            print(\"ğŸ‘‹ Thank you for using the Enhanced Skin Analysis System!\")\n",
        "            break\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\nğŸ“‹ Analysis History:\")\n",
        "            conversations = memory_manager.conversation_history\n",
        "            if not conversations:\n",
        "                print(\"   No analyses yet.\")\n",
        "            else:\n",
        "                for i, conv in enumerate(conversations, 1):\n",
        "                    print(f\"\\n   {i}. Time: {conv['timestamp']}\")\n",
        "                    print(f\"      User: {conv['user'][:50]}...\")\n",
        "                    print(f\"      AI: {conv['ai'][:50]}...\")\n",
        "            continue\n",
        "\n",
        "        elif choice == '3':\n",
        "            # Direct database query\n",
        "            query = input(\"Enter your question about skin conditions: \").strip()\n",
        "            if query:\n",
        "                response = skin_db.query_database(query)\n",
        "                print(f\"\\nğŸ¤– Database Response: {response}\")\n",
        "                memory_manager.add_interaction(f\"Database query: {query}\", response)\n",
        "            continue\n",
        "\n",
        "\n",
        "        elif choice == '4':\n",
        "            memory_manager.clear_memory()\n",
        "            print(\"ğŸ—‘ï¸ History cleared!\")\n",
        "            continue\n",
        "\n",
        "        elif choice == '1':\n",
        "            # Upload and process image\n",
        "            image_data = upload_skin_image()\n",
        "            if not image_data:\n",
        "                continue\n",
        "\n",
        "            conversation_count += 1\n",
        "            conversation_id = f\"skin_analysis_{conversation_count}_{datetime.now().strftime('%H%M%S')}\"\n",
        "\n",
        "            print(f\"\\nğŸ” Analyzing skin condition (ID: {conversation_id})...\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            try:\n",
        "                # Initialize state\n",
        "                initial_state = {\n",
        "                    \"image_data\": image_data,\n",
        "                    \"image_description\": \"\",\n",
        "                    \"symptoms\": [],\n",
        "                    \"skin_tone\": \"\",\n",
        "                    \"affected_area\": \"\",\n",
        "                    \"severity_level\": \"\",\n",
        "                    \"possible_conditions\": [],\n",
        "                    \"confidence_score\": 0.0,\n",
        "                    \"recommended_actions\": [],\n",
        "                    \"emergency_flag\": False,\n",
        "                    \"conversation_history\": [],\n",
        "                    \"user_api_key\": api_manager.gemini_key or api_manager.gpt_key,\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"current_query\": \"\",\n",
        "                    \"database_context\": \"\",\n",
        "                    # \"memory_context\": \"\" # Removed this as memory_context is not in state\n",
        "                }\n",
        "\n",
        "                # Process through the graph\n",
        "                result = skin_analysis_app.invoke(initial_state)\n",
        "\n",
        "                # Display results\n",
        "                print(\"\\n\" + \"=\" * 60)\n",
        "                print(\"ğŸ“Š ENHANCED SKIN ANALYSIS RESULTS:\")\n",
        "                print(\"=\" * 60)\n",
        "                print(f\"ğŸ©º Symptoms Identified: {', '.join(result['symptoms'])}\")\n",
        "                print(f\"ğŸ¨ Skin Tone: {result['skin_tone']}\")\n",
        "                print(f\"ğŸ“ Affected Area: {result['affected_area']}\")\n",
        "                print(f\"âš ï¸  Severity Level: {result['severity_level']}\")\n",
        "                print(f\"ğŸ” Possible Conditions: {', '.join(result['possible_conditions'])}\")\n",
        "                print(f\"ğŸ“ˆ Confidence Score: {result['confidence_score']:.2f}\")\n",
        "\n",
        "                if result['database_context']:\n",
        "                    print(f\"ğŸ’¾ Database Insights: {result['database_context']}\") # Display full database context\n",
        "\n",
        "\n",
        "                if result['emergency_flag']:\n",
        "                    print(\"\\nğŸš¨ EMERGENCY ALERT!\")\n",
        "                    print(\"This condition may require immediate medical attention!\")\n",
        "\n",
        "                print(\"\\nğŸ’¡ RECOMMENDED ACTIONS:\")\n",
        "                for i, action in enumerate(result['recommended_actions'], 1):\n",
        "                    print(f\"   {i}. {action}\")\n",
        "\n",
        "                # Follow-up conversation\n",
        "                follow_up_conversation(result)\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error during analysis: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc() # Print traceback for debugging\n",
        "\n",
        "        else:\n",
        "            print(\"âŒ Invalid option. Please try again.\")\n",
        "\n",
        "\n",
        "def follow_up_conversation(analysis_result):\n",
        "    \"\"\"Enhanced conversation with database and memory integration\"\"\"\n",
        "    print(\"\\nğŸ’¬ AI Assistant is ready to answer your questions!\")\n",
        "    print(\"You can ask about:\")\n",
        "    print(\"â€¢ Specific skin conditions\")\n",
        "    print(\"â€¢ Treatment options\")\n",
        "    print(\"â€¢ Symptom explanations\")\n",
        "    print(\"â€¢ Prevention tips\")\n",
        "    print(\"â€¢ Type 'quit' to return to main menu\")\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"\\nğŸ’­ Your question: \").strip()\n",
        "\n",
        "        if user_question.lower() in ['quit', 'exit', '5']:\n",
        "            break\n",
        "\n",
        "        if not user_question:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Get relevant context from memory and database\n",
        "            memory_context = memory_manager.get_conversation_context(user_question)\n",
        "            database_response = skin_db.query_database(user_question) # Query database based on user question\n",
        "\n",
        "\n",
        "            # Create enhanced prompt with all available information\n",
        "            enhanced_prompt = f\"\"\"\n",
        "            Based on the previous skin analysis and conversation history, answer the user's question.\n",
        "\n",
        "            PREVIOUS ANALYSIS:\n",
        "            - Symptoms: {analysis_result['symptoms']}\n",
        "            - Possible Conditions: {analysis_result['possible_conditions']}\n",
        "            - Severity: {analysis_result['severity_level']}\n",
        "            - Database Context from analysis: {analysis_result['database_context']}\n",
        "\n",
        "            ADDITIONAL DATABASE CONTEXT (if relevant to current question):\n",
        "            {database_response}\n",
        "\n",
        "            CONVERSATION HISTORY:\n",
        "            {memory_context}\n",
        "\n",
        "            USER'S CURRENT QUESTION: {user_question}\n",
        "\n",
        "            Please provide a helpful, accurate, and empathetic response. If you're unsure, recommend consulting a healthcare professional.\n",
        "            \"\"\"\n",
        "\n",
        "            llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
        "            response = llm.invoke(enhanced_prompt)\n",
        "\n",
        "            print(f\"\\nğŸ¤– AI Assistant: {response.content}\")\n",
        "\n",
        "            # Store the interaction in memory\n",
        "            memory_manager.add_interaction(user_question, response.content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error generating response: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc() # Print traceback for debugging\n",
        "\n",
        "# --- 9. Run the Enhanced System ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸŒŸ ENHANCED AI Skin Disease Analysis System ğŸŒŸ\")\n",
        "    print(\"This tool provides preliminary analysis but is NOT a substitute for professional medical advice.\")\n",
        "    print(\"Always consult healthcare providers for proper diagnosis and treatment.\\n\")\n",
        "\n",
        "    chat_interface()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XMljIZfwAEge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -qU langchain-google-genai langchain google-generativeai pillow\n",
        "\n",
        "# Import required modules\n",
        "import os\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# --- 1. Modern API Manager with Model Discovery ---\n",
        "class APIKeyManager:\n",
        "    def __init__(self):\n",
        "        self.gemini_key = None\n",
        "        self.available_models = []\n",
        "\n",
        "    def set_gemini_key(self, key):\n",
        "        self.gemini_key = key\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = key\n",
        "        genai.configure(api_key=key)\n",
        "        print(\"ğŸ”‘ API configuration completed successfully\")\n",
        "        self.discover_available_models()\n",
        "\n",
        "    def discover_available_models(self):\n",
        "        \"\"\"Discover available models for the current API key\"\"\"\n",
        "        try:\n",
        "            models = genai.list_models()\n",
        "            self.available_models = []\n",
        "\n",
        "            for model in models:\n",
        "                model_name = model.name.split('/')[-1]\n",
        "                # Filter for models that support generateContent\n",
        "                if 'generateContent' in model.supported_generation_methods:\n",
        "                    self.available_models.append(model_name)\n",
        "\n",
        "            print(f\"ğŸ“‹ Available models: {', '.join(self.available_models)}\")\n",
        "\n",
        "            # Set preferred model order\n",
        "            self.preferred_models = [\n",
        "                'gemini-1.5-flash',\n",
        "                'gemini-1.5-pro',\n",
        "                'gemini-pro',\n",
        "                'gemini-pro-vision'\n",
        "            ]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Could not discover models: {e}\")\n",
        "            # Fallback to common models\n",
        "            self.available_models = ['gemini-pro', 'gemini-pro-vision']\n",
        "            self.preferred_models = ['gemini-pro', 'gemini-pro-vision']\n",
        "\n",
        "    def get_best_model(self):\n",
        "        \"\"\"Get the best available model\"\"\"\n",
        "        for model in self.preferred_models:\n",
        "            if model in self.available_models:\n",
        "                return model\n",
        "        return self.available_models[0] if self.available_models else 'gemini-pro'\n",
        "\n",
        "api_manager = APIKeyManager()\n",
        "\n",
        "# --- 2. Modern Conversation Memory ---\n",
        "class ConversationMemory:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "        self.current_session = []\n",
        "\n",
        "    def add_exchange(self, user_input: str, ai_response: str, analysis_context: str = \"\"):\n",
        "        \"\"\"Add a conversation exchange with timestamp\"\"\"\n",
        "        exchange = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"user\": user_input,\n",
        "            \"assistant\": ai_response,\n",
        "            \"context\": analysis_context,\n",
        "            \"session_id\": len(self.history) + 1\n",
        "        }\n",
        "        self.history.append(exchange)\n",
        "        self.current_session.append(exchange)\n",
        "        print(f\"ğŸ’¾ Memory updated: {len(self.history)} total exchanges\")\n",
        "\n",
        "    def get_recent_context(self, max_exchanges: int = 6) -> str:\n",
        "        \"\"\"Get recent conversation context for continuity\"\"\"\n",
        "        if not self.history:\n",
        "            return \"No previous conversation history available.\"\n",
        "\n",
        "        recent = self.history[-max_exchanges:]\n",
        "        context_lines = []\n",
        "\n",
        "        for exchange in recent:\n",
        "            context_lines.append(f\"User: {exchange['user']}\")\n",
        "            context_lines.append(f\"Assistant: {exchange['assistant']}\")\n",
        "            if exchange['context']:\n",
        "                context_lines.append(f\"Context: {exchange['context']}\")\n",
        "            context_lines.append(\"---\")\n",
        "\n",
        "        return \"\\n\".join(context_lines)\n",
        "\n",
        "    def clear_current_session(self):\n",
        "        \"\"\"Clear current session while preserving history\"\"\"\n",
        "        self.current_session = []\n",
        "        print(\"ğŸ”„ Current session cleared\")\n",
        "\n",
        "memory = ConversationMemory()\n",
        "\n",
        "# --- 3. Image Processing Engine ---\n",
        "class ImageProcessor:\n",
        "    @staticmethod\n",
        "    def prepare_image(image_file, max_size=(512, 512)) -> str:\n",
        "        \"\"\"Process and optimize image for analysis\"\"\"\n",
        "        try:\n",
        "            # Handle both file paths and uploaded bytes\n",
        "            if isinstance(image_file, str):\n",
        "                # It's a file path\n",
        "                with open(image_file, \"rb\") as img_file:\n",
        "                    image_bytes = img_file.read()\n",
        "            elif hasattr(image_file, 'read'):\n",
        "                # It's a file-like object\n",
        "                image_bytes = image_file.read()\n",
        "            else:\n",
        "                # It's already bytes (from Colab upload)\n",
        "                image_bytes = image_file\n",
        "\n",
        "            print(f\"ğŸ“Š Image size: {len(image_bytes)} bytes\")\n",
        "\n",
        "            # Process image\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            original_size = image.size\n",
        "            print(f\"ğŸ“ Original dimensions: {original_size}\")\n",
        "\n",
        "            image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
        "            new_size = image.size\n",
        "            print(f\"ğŸ“ Resized to: {new_size}\")\n",
        "\n",
        "            buffered = io.BytesIO()\n",
        "            image.save(buffered, format=\"JPEG\", quality=90)\n",
        "            processed_bytes = buffered.getvalue()\n",
        "            print(f\"âœ… Image processed: {len(processed_bytes)} bytes final size\")\n",
        "\n",
        "            return base64.b64encode(processed_bytes).decode('utf-8')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Image processing error: {e}\")\n",
        "            raise\n",
        "\n",
        "# --- 4. Modern Skin Analysis Core with FALLBACK MODELS ---\n",
        "class SkinAnalysisCore:\n",
        "    def __init__(self):\n",
        "        self.llm = None\n",
        "        self.vision_model = None\n",
        "        self.model_name = None\n",
        "\n",
        "    def initialize_models(self):\n",
        "        \"\"\"Initialize AI models with fallback support\"\"\"\n",
        "        try:\n",
        "            # Get the best available model\n",
        "            self.model_name = api_manager.get_best_model()\n",
        "            print(f\"ğŸ¤– Using model: {self.model_name}\")\n",
        "\n",
        "            # Initialize LLM for text\n",
        "            self.llm = ChatGoogleGenerativeAI(\n",
        "                model=self.model_name,\n",
        "                temperature=0.7,\n",
        "                max_output_tokens=1000\n",
        "            )\n",
        "\n",
        "            # Initialize vision model (use same model for simplicity)\n",
        "            self.vision_model = genai.GenerativeModel(self.model_name)\n",
        "\n",
        "            print(\"âœ… AI models initialized successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Model initialization failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def analyze_skin_image(self, image_data: str) -> Dict:\n",
        "        \"\"\"Comprehensive skin image analysis with verbose output\"\"\"\n",
        "        print(\"ğŸ” Initiating high-resolution skin analysis...\")\n",
        "\n",
        "        try:\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "            analysis_prompt = \"\"\"\n",
        "            Conduct a thorough dermatological analysis of this skin image with exceptional attention to detail:\n",
        "\n",
        "            Please provide an extensive, verbose examination covering:\n",
        "\n",
        "            VISUAL CHARACTERISTICS:\n",
        "            â€¢ Skin texture and surface morphology\n",
        "            â€¢ Pigmentation patterns and color variations\n",
        "            â€¢ Vascular appearance and erythema presence\n",
        "            â€¢ Lesion morphology if present\n",
        "            â€¢ Surface integrity and any disruptions\n",
        "\n",
        "            CLINICAL OBSERVATIONS:\n",
        "            â€¢ Primary visible manifestations\n",
        "            â€¢ Distribution patterns across the affected area\n",
        "            â€¢ Border characteristics and definition\n",
        "            â€¢ Symmetry or asymmetry of presentation\n",
        "            â€¢ Any exudate, scaling, or crust formation\n",
        "\n",
        "            ASSESSMENT PARAMETERS:\n",
        "            â€¢ Apparent severity gradient\n",
        "            â€¢ Potential inflammatory indicators\n",
        "            â€¢ Chronic versus acute presentation cues\n",
        "            â€¢ Anatomical location implications\n",
        "\n",
        "            Provide this analysis with comprehensive medical terminology while maintaining clinical objectivity.\n",
        "            Be exceptionally thorough in your visual inventory of the skin presentation.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.vision_model.generate_content([analysis_prompt, image])\n",
        "            print(\"âœ… Deep image analysis completed successfully\")\n",
        "\n",
        "            return {\n",
        "                \"raw_analysis\": response.text,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"status\": \"completed\",\n",
        "                \"model_used\": self.model_name\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Analysis failure: {e}\")\n",
        "            # Provide a fallback analysis\n",
        "            fallback_analysis = \"\"\"\n",
        "            Based on the uploaded skin image, I can observe visible dermatological features that warrant discussion.\n",
        "            The image shows skin manifestations that should be evaluated by a healthcare professional for accurate diagnosis.\n",
        "\n",
        "            Key observations include visible skin texture variations and potential inflammatory signs that could indicate\n",
        "            various dermatological conditions. A professional evaluation is recommended for proper assessment.\n",
        "            \"\"\"\n",
        "\n",
        "            return {\n",
        "                \"raw_analysis\": fallback_analysis,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"status\": \"fallback\",\n",
        "                \"model_used\": \"fallback\"\n",
        "            }\n",
        "\n",
        "    def extract_structured_findings(self, analysis_text: str) -> Dict:\n",
        "        \"\"\"Extract structured findings from verbose analysis\"\"\"\n",
        "        print(\"ğŸ“Š Processing structured findings extraction...\")\n",
        "\n",
        "        # Initialize findings with default values\n",
        "        findings = {\n",
        "            \"primary_manifestations\": [\"Skin texture variations\", \"Visible dermatological features\"],\n",
        "            \"symptom_catalog\": [\"Requires professional evaluation\"],\n",
        "            \"clinical_impressions\": [\"Further assessment recommended\"],\n",
        "            \"urgency_assessment\": \"Consult healthcare provider\",\n",
        "            \"analysis_quality\": \"Basic\"\n",
        "        }\n",
        "\n",
        "        # If we have a real analysis, process it\n",
        "        if \"fallback\" not in analysis_text.lower():\n",
        "            extraction_prompt = f\"\"\"\n",
        "            Based on this comprehensive skin analysis, extract and structure the key findings:\n",
        "\n",
        "            ANALYSIS TEXT:\n",
        "            {analysis_text}\n",
        "\n",
        "            Please organize findings into these precise categories:\n",
        "\n",
        "            PRIMARY MANIFESTATIONS:\n",
        "            - List all observable skin changes\n",
        "            - Note texture alterations\n",
        "            - Document color variations\n",
        "\n",
        "            SYMPTOM CATALOG:\n",
        "            - Enumerate all detectable symptoms\n",
        "            - Rate apparent severity\n",
        "            - Note distribution patterns\n",
        "\n",
        "            CLINICAL IMPRESSIONS:\n",
        "            - Potential condition categories\n",
        "            - Urgency level assessment\n",
        "            - Recommended focus areas\n",
        "\n",
        "            Provide this as a structured yet comprehensive summary.\n",
        "            \"\"\"\n",
        "\n",
        "            try:\n",
        "                response = self.llm.invoke(extraction_prompt)\n",
        "\n",
        "                # Reset findings with actual data\n",
        "                findings = {\n",
        "                    \"primary_manifestations\": [],\n",
        "                    \"symptom_catalog\": [],\n",
        "                    \"clinical_impressions\": [],\n",
        "                    \"urgency_assessment\": \"Moderate\",\n",
        "                    \"analysis_quality\": \"Detailed\"\n",
        "                }\n",
        "\n",
        "                # Simple parsing\n",
        "                lines = response.content.split('\\n')\n",
        "                current_section = None\n",
        "\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if 'PRIMARY MANIFESTATIONS' in line.upper():\n",
        "                        current_section = 'primary_manifestations'\n",
        "                    elif 'SYMPTOM CATALOG' in line.upper():\n",
        "                        current_section = 'symptom_catalog'\n",
        "                    elif 'CLINICAL IMPRESSIONS' in line.upper():\n",
        "                        current_section = 'clinical_impressions'\n",
        "                    elif line.startswith('-') and current_section:\n",
        "                        findings[current_section].append(line[1:].strip())\n",
        "                    elif 'URGENCY' in line.upper() and 'ASSESSMENT' in line.upper():\n",
        "                        if 'high' in line.lower():\n",
        "                            findings['urgency_assessment'] = \"High\"\n",
        "                        elif 'low' in line.lower():\n",
        "                            findings['urgency_assessment'] = \"Low\"\n",
        "\n",
        "                print(\"âœ… Structured findings extracted successfully\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  Findings extraction limited: {e}\")\n",
        "                findings[\"analysis_quality\"] = \"Limited\"\n",
        "\n",
        "        return findings\n",
        "\n",
        "# --- 5. Modern Conversation Initiator ---\n",
        "class ConversationInitiator:\n",
        "    def __init__(self, analysis_core: SkinAnalysisCore):\n",
        "        self.analysis_core = analysis_core\n",
        "\n",
        "    def create_warm_introduction(self, findings: Dict) -> str:\n",
        "        \"\"\"Create a warm, engaging introduction based on analysis\"\"\"\n",
        "        print(\"ğŸ’« Crafting personalized conversation introduction...\")\n",
        "\n",
        "        try:\n",
        "            if findings.get(\"analysis_quality\") == \"Detailed\":\n",
        "                intro_prompt = f\"\"\"\n",
        "                Based on these detailed skin analysis findings, create a warm, engaging, and professional conversation opener:\n",
        "\n",
        "                ANALYSIS FINDINGS:\n",
        "                {findings}\n",
        "\n",
        "                Please craft an introduction that:\n",
        "                1. Starts with a warm, empathetic greeting\n",
        "                2. Acknowledges the user's initiative in seeking analysis\n",
        "                3. Briefly highlights 2-3 key observations from the analysis\n",
        "                4. Invites conversation about their concerns\n",
        "                5. Offers support and guidance\n",
        "\n",
        "                Use a conversational yet professional tone.\n",
        "                \"\"\"\n",
        "\n",
        "                response = self.analysis_core.llm.invoke(intro_prompt)\n",
        "                introduction = response.content\n",
        "            else:\n",
        "                introduction = \"\"\"Hello! Thank you for sharing your skin image.\n",
        "\n",
        "I can see this is an image of a skin condition that deserves careful attention. While I can provide general information and discuss common skin concerns, I want to emphasize that proper diagnosis should come from a healthcare professional.\n",
        "\n",
        "What specific aspects of your skin concern would you like to discuss today? I'm here to provide information and support while we explore this together.\"\"\"\n",
        "\n",
        "            print(\"âœ… Conversation initiation crafted successfully\")\n",
        "            return introduction\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Using fallback introduction: {e}\")\n",
        "            return \"\"\"Welcome! Thank you for sharing your skin image with me.\n",
        "\n",
        "I'm here to help you understand skin conditions and provide general information. Let's discuss what you're experiencing - please feel free to share any specific concerns or questions you have about your skin.\"\"\"\n",
        "\n",
        "# --- 6. Main Application ---\n",
        "def main():\n",
        "    print(\"\"\"\n",
        "    ğŸ¯ MODERN SKIN ANALYSIS CONVERSATION SYSTEM\n",
        "    ===========================================\n",
        "    Advanced AI-powered skin analysis with:\n",
        "    â€¢ Persistent memory across conversations\n",
        "    â€¢ Verbose, detailed responses\n",
        "    â€¢ Context-aware interactions\n",
        "    â€¢ Modern conversational interface\n",
        "    \"\"\")\n",
        "\n",
        "    # Initialize API\n",
        "    api_manager = APIKeyManager()\n",
        "    gemini_key = input(\"ğŸ”‘ Enter your Google Gemini API key: \").strip()\n",
        "\n",
        "    if not gemini_key:\n",
        "        print(\"âŒ API key is required. Please restart and provide a valid API key.\")\n",
        "        return\n",
        "\n",
        "    api_manager.set_gemini_key(gemini_key)\n",
        "\n",
        "    # Initialize core components\n",
        "    image_processor = ImageProcessor()\n",
        "    analysis_core = SkinAnalysisCore()\n",
        "\n",
        "    if not analysis_core.initialize_models():\n",
        "        print(\"âŒ Failed to initialize AI models. Please check your API key and try again.\")\n",
        "        return\n",
        "\n",
        "    conversation_initiator = ConversationInitiator(analysis_core)\n",
        "    current_analysis = None\n",
        "\n",
        "    print(f\"\\nğŸŒŸ Assistant ready! Using model: {analysis_core.model_name}\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nğŸ”„ Main Menu:\")\n",
        "        print(\"1. Upload and analyze skin image\")\n",
        "        print(\"2. View conversation history\")\n",
        "        print(\"3. Clear current session\")\n",
        "        print(\"4. Exit application\")\n",
        "\n",
        "        choice = input(\"\\nğŸ¯ Select option (1-4): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                print(\"\\nğŸ“¤ Please upload your skin image...\")\n",
        "                uploaded = files.upload()\n",
        "\n",
        "                if not uploaded:\n",
        "                    print(\"âŒ No files uploaded\")\n",
        "                    continue\n",
        "\n",
        "                file_name = list(uploaded.keys())[0]\n",
        "                file_content = uploaded[file_name]\n",
        "\n",
        "                print(f\"âœ… File '{file_name}' uploaded successfully ({len(file_content)} bytes)\")\n",
        "\n",
        "                # Process image\n",
        "                print(\"\\nğŸ“¸ Processing your skin image...\")\n",
        "                image_data = image_processor.prepare_image(file_content)\n",
        "                print(\"âœ… Image optimized for analysis\")\n",
        "\n",
        "                # Analyze image\n",
        "                analysis_result = analysis_core.analyze_skin_image(image_data)\n",
        "                print(\"âœ… Analysis completed\")\n",
        "\n",
        "                # Extract findings\n",
        "                findings = analysis_core.extract_structured_findings(analysis_result[\"raw_analysis\"])\n",
        "                print(\"âœ… Findings processed\")\n",
        "\n",
        "                # Store current analysis\n",
        "                current_analysis = {\n",
        "                    \"image_analysis\": analysis_result,\n",
        "                    \"structured_findings\": findings,\n",
        "                    \"processed_at\": datetime.now().isoformat()\n",
        "                }\n",
        "\n",
        "                # Initiate conversation\n",
        "                introduction = conversation_initiator.create_warm_introduction(findings)\n",
        "\n",
        "                print(\"\\n\" + \"=\" * 70)\n",
        "                print(\"ğŸ¤– MODERN SKIN ASSISTANT:\")\n",
        "                print(\"=\" * 70)\n",
        "                print(introduction)\n",
        "                print(\"=\" * 70)\n",
        "\n",
        "                # Store in memory\n",
        "                memory.add_exchange(\n",
        "                    user_input=\"Uploaded skin image for analysis\",\n",
        "                    ai_response=introduction,\n",
        "                    analysis_context=f\"Skin analysis using {analysis_result.get('model_used', 'unknown')}\"\n",
        "                )\n",
        "\n",
        "                # Start conversation\n",
        "                print(\"\\nğŸ’¬ Conversation session activated...\")\n",
        "                print(\"I can discuss your skin analysis, answer questions, or provide guidance.\")\n",
        "                print(\"Type 'exit' to end this conversation session.\\n\")\n",
        "\n",
        "                while True:\n",
        "                    user_input = input(\"ğŸ‘¤ You: \").strip()\n",
        "\n",
        "                    if user_input.lower() in ['exit', 'quit', 'end', 'back']:\n",
        "                        print(\"\\nğŸ”„ Ending conversation session...\")\n",
        "                        break\n",
        "\n",
        "                    if not user_input:\n",
        "                        continue\n",
        "\n",
        "                    # Simple response system without LLM for reliability\n",
        "                    memory_context = memory.get_recent_context()\n",
        "\n",
        "                    if \"condition\" in user_input.lower() or \"diagnosis\" in user_input.lower():\n",
        "                        response = \"\"\"Based on the image analysis, I can see visible skin characteristics that should be evaluated by a dermatologist.\n",
        "\n",
        "Common skin conditions that share similar appearances might include rosacea, eczema, or other inflammatory conditions. However, only a healthcare professional can provide an accurate diagnosis through proper examination.\n",
        "\n",
        "Would you like me to discuss general skin care tips or common characteristics of skin conditions?\"\"\"\n",
        "\n",
        "                    elif \"treatment\" in user_input.lower() or \"cure\" in user_input.lower():\n",
        "                        response = \"\"\"Treatment approaches depend entirely on an accurate diagnosis.\n",
        "\n",
        "General skin care recommendations include:\n",
        "â€¢ Using gentle, fragrance-free skincare products\n",
        "â€¢ Avoiding known irritants\n",
        "â€¢ Protecting skin from sun exposure\n",
        "â€¢ Maintaining proper hydration\n",
        "\n",
        "For specific treatment plans, please consult with a healthcare provider who can examine your skin directly.\"\"\"\n",
        "\n",
        "                    elif \"symptom\" in user_input.lower() or \"sign\" in user_input.lower():\n",
        "                        response = \"\"\"From the image analysis, I observe features that commonly relate to various skin conditions.\n",
        "\n",
        "Key observations often include:\n",
        "â€¢ Skin texture changes\n",
        "â€¢ Color variations or redness\n",
        "â€¢ Potential inflammation signs\n",
        "â€¢ Surface characteristics\n",
        "\n",
        "What specific symptoms are you most concerned about?\"\"\"\n",
        "\n",
        "                    else:\n",
        "                        response = f\"\"\"Thank you for your question about \"{user_input}\".\n",
        "\n",
        "I'm designed to provide general information about skin health and discuss common concerns. For personalized medical advice, I recommend consulting with a healthcare professional who can examine your skin directly.\n",
        "\n",
        "Is there something specific about skin conditions or skin care you'd like to learn more about?\"\"\"\n",
        "\n",
        "                    print(f\"\\nğŸ¤– Assistant: {response}\\n\")\n",
        "\n",
        "                    # Store exchange\n",
        "                    memory.add_exchange(\n",
        "                        user_input=user_input,\n",
        "                        ai_response=response,\n",
        "                        analysis_context=\"General skin health conversation\"\n",
        "                    )\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"âŒ Colab environment required for file uploads\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error: {e}\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\nğŸ“š Conversation History:\")\n",
        "            if memory.history:\n",
        "                for i, exchange in enumerate(memory.history[-5:], 1):\n",
        "                    print(f\"\\n--- Exchange {exchange['session_id']} ---\")\n",
        "                    print(f\"ğŸ‘¤: {exchange['user'][:80]}...\")\n",
        "                    print(f\"ğŸ¤–: {exchange['assistant'][:80]}...\")\n",
        "                    print(f\"ğŸ•’: {exchange['timestamp']}\")\n",
        "            else:\n",
        "                print(\"No conversation history yet\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            memory.clear_current_session()\n",
        "            current_analysis = None\n",
        "            print(\"ğŸ”„ Current session cleared. Memory history preserved.\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"\\nğŸ‘‹ Thank you for using the Modern Skin Analysis Assistant!\")\n",
        "            print(\"ğŸ’¾ Your conversation history has been preserved.\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"âŒ Please select a valid option (1-4)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "VS0aLUY5mXp9",
        "outputId": "e423475b-f614-4daf-ad01-6024041eb255"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "    ğŸ¯ MODERN SKIN ANALYSIS CONVERSATION SYSTEM\n",
            "    ===========================================\n",
            "    Advanced AI-powered skin analysis with:\n",
            "    â€¢ Persistent memory across conversations\n",
            "    â€¢ Verbose, detailed responses\n",
            "    â€¢ Context-aware interactions\n",
            "    â€¢ Modern conversational interface\n",
            "    \n",
            "ğŸ”‘ Enter your Google Gemini API key: AIzaSyCR8xhkE6XNCdgmgRJFtKyodhsMz5jfbQE\n",
            "ğŸ”‘ API configuration completed successfully\n",
            "ğŸ“‹ Available models: gemini-2.5-pro-preview-03-25, gemini-2.5-flash-preview-05-20, gemini-2.5-flash, gemini-2.5-flash-lite-preview-06-17, gemini-2.5-pro-preview-05-06, gemini-2.5-pro-preview-06-05, gemini-2.5-pro, gemini-2.0-flash-exp, gemini-2.0-flash, gemini-2.0-flash-001, gemini-2.0-flash-exp-image-generation, gemini-2.0-flash-lite-001, gemini-2.0-flash-lite, gemini-2.0-flash-preview-image-generation, gemini-2.0-flash-lite-preview-02-05, gemini-2.0-flash-lite-preview, gemini-2.0-pro-exp, gemini-2.0-pro-exp-02-05, gemini-exp-1206, gemini-2.0-flash-thinking-exp-01-21, gemini-2.0-flash-thinking-exp, gemini-2.0-flash-thinking-exp-1219, gemini-2.5-flash-preview-tts, gemini-2.5-pro-preview-tts, learnlm-2.0-flash-experimental, gemma-3-1b-it, gemma-3-4b-it, gemma-3-12b-it, gemma-3-27b-it, gemma-3n-e4b-it, gemma-3n-e2b-it, gemini-flash-latest, gemini-flash-lite-latest, gemini-pro-latest, gemini-2.5-flash-lite, gemini-2.5-flash-image-preview, gemini-2.5-flash-image, gemini-2.5-flash-preview-09-2025, gemini-2.5-flash-lite-preview-09-2025, gemini-robotics-er-1.5-preview\n",
            "âŒ Model initialization failed: 'APIKeyManager' object has no attribute 'preferred_models'\n",
            "âŒ Failed to initialize AI models. Please check your API key and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -qU langchain-google-genai langchain google-generativeai pillow\n",
        "\n",
        "# Import required modules\n",
        "import os\n",
        "import base64\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Generator\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# --- 1. Fixed API Manager with Correct Models ---\n",
        "class APIKeyManager:\n",
        "    def __init__(self):\n",
        "        self.gemini_key = None\n",
        "        self.available_models = []\n",
        "        # Use the models that are actually available in your API\n",
        "        self.preferred_models = [\n",
        "            'gemini-2.5-flash-preview-05-20',\n",
        "            'gemini-2.5-flash',\n",
        "            'gemini-2.5-pro-preview-03-25',\n",
        "            'gemini-2.0-flash'\n",
        "        ]\n",
        "\n",
        "    def set_gemini_key(self, key):\n",
        "        self.gemini_key = key\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = key\n",
        "        genai.configure(api_key=key)\n",
        "        print(\"ğŸ”‘ API configuration completed successfully\")\n",
        "        self.discover_available_models()\n",
        "\n",
        "    def discover_available_models(self):\n",
        "        \"\"\"Discover available models for the current API key\"\"\"\n",
        "        try:\n",
        "            models = genai.list_models()\n",
        "            self.available_models = []\n",
        "\n",
        "            for model in models:\n",
        "                model_name = model.name.split('/')[-1]\n",
        "                if 'generateContent' in model.supported_generation_methods:\n",
        "                    self.available_models.append(model_name)\n",
        "\n",
        "            print(f\"ğŸ“‹ Available models: {', '.join(self.available_models)}\")\n",
        "\n",
        "            # Find which preferred models are actually available\n",
        "            available_preferred = [model for model in self.preferred_models if model in self.available_models]\n",
        "            if available_preferred:\n",
        "                self.preferred_models = available_preferred\n",
        "                print(f\"âœ… Using preferred models: {', '.join(self.preferred_models)}\")\n",
        "            else:\n",
        "                self.preferred_models = self.available_models[:3]\n",
        "                print(f\"âš ï¸ Using available models: {', '.join(self.preferred_models)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Could not discover models: {e}\")\n",
        "            # Fallback to known available models from your list\n",
        "            self.available_models = ['gemini-2.5-flash', 'gemini-2.5-pro-preview-03-25']\n",
        "            self.preferred_models = ['gemini-2.5-flash', 'gemini-2.5-pro-preview-03-25']\n",
        "\n",
        "    def get_best_model(self):\n",
        "        \"\"\"Get the best available model\"\"\"\n",
        "        for model in self.preferred_models:\n",
        "            if model in self.available_models:\n",
        "                print(f\"ğŸ¯ Selected model: {model}\")\n",
        "                return model\n",
        "        return self.available_models[0] if self.available_models else 'gemini-2.5-flash'\n",
        "\n",
        "api_manager = APIKeyManager()\n",
        "\n",
        "# --- 2. Memory System ---\n",
        "class SkinRashMemory:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "        self.current_session = []\n",
        "        self.uploaded_images = {}\n",
        "        print(\"ğŸ’¾ Skin rash memory system initialized\")\n",
        "\n",
        "    def add_exchange(self, user_input: str, ai_response: str, analysis_context: str = \"\", image_data: Dict = None):\n",
        "        \"\"\"Add a conversation exchange with timestamp\"\"\"\n",
        "        exchange = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"user\": user_input,\n",
        "            \"assistant\": ai_response,\n",
        "            \"context\": analysis_context,\n",
        "            \"session_id\": len(self.history) + 1,\n",
        "            \"image_reference\": image_data\n",
        "        }\n",
        "        self.history.append(exchange)\n",
        "        self.current_session.append(exchange)\n",
        "        print(f\"ğŸ’¾ Memory updated: {len(self.history)} total exchanges\")\n",
        "\n",
        "    def store_image_analysis(self, image_id: str, analysis: Dict, findings: Dict):\n",
        "        \"\"\"Store image analysis for future reference\"\"\"\n",
        "        self.uploaded_images[image_id] = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"analysis\": analysis,\n",
        "            \"findings\": findings\n",
        "        }\n",
        "        print(f\"ğŸ–¼ï¸ Skin rash analysis stored: {image_id}\")\n",
        "\n",
        "    def get_recent_context(self, max_exchanges: int = 8) -> str:\n",
        "        \"\"\"Get recent conversation context\"\"\"\n",
        "        if not self.history:\n",
        "            return \"No previous conversation about skin rashes.\"\n",
        "\n",
        "        recent = self.history[-max_exchanges:]\n",
        "        context_lines = [\"RECENT SKIN RASH CONVERSATION:\"]\n",
        "\n",
        "        for exchange in recent:\n",
        "            context_lines.append(f\"[{exchange['timestamp'][11:19]}] User: {exchange['user']}\")\n",
        "            context_lines.append(f\"[{exchange['timestamp'][11:19]}] Assistant: {exchange['assistant'][:100]}...\")\n",
        "            context_lines.append(\"---\")\n",
        "\n",
        "        return \"\\n\".join(context_lines)\n",
        "\n",
        "    def get_image_references(self) -> List[Dict]:\n",
        "        \"\"\"Get all uploaded image references\"\"\"\n",
        "        return [{\"id\": img_id, **data} for img_id, data in self.uploaded_images.items()]\n",
        "\n",
        "    def clear_current_session(self):\n",
        "        self.current_session = []\n",
        "        print(\"ğŸ”„ Current skin rash session cleared\")\n",
        "\n",
        "memory = SkinRashMemory()\n",
        "\n",
        "# --- 3. Skin Rash Image Processor ---\n",
        "class SkinRashImageProcessor:\n",
        "    @staticmethod\n",
        "    def prepare_image(image_file, max_size=(512, 512)) -> str:\n",
        "        \"\"\"Process and optimize image for rash analysis\"\"\"\n",
        "        try:\n",
        "            if isinstance(image_file, str):\n",
        "                with open(image_file, \"rb\") as img_file:\n",
        "                    image_bytes = img_file.read()\n",
        "            elif hasattr(image_file, 'read'):\n",
        "                image_bytes = image_file.read()\n",
        "            else:\n",
        "                image_bytes = image_file\n",
        "\n",
        "            print(f\"ğŸ“Š Processing skin rash image: {len(image_bytes)} bytes\")\n",
        "\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            original_size = image.size\n",
        "            print(f\"ğŸ“ Original dimensions: {original_size}\")\n",
        "\n",
        "            image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
        "            new_size = image.size\n",
        "            print(f\"ğŸ“ Optimized for rash analysis: {new_size}\")\n",
        "\n",
        "            buffered = io.BytesIO()\n",
        "            image.save(buffered, format=\"JPEG\", quality=90)\n",
        "            processed_bytes = buffered.getvalue()\n",
        "            print(f\"âœ… Skin rash image ready for analysis: {len(processed_bytes)} bytes\")\n",
        "\n",
        "            return base64.b64encode(processed_bytes).decode('utf-8')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Skin rash image processing error: {e}\")\n",
        "            raise\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_image_id() -> str:\n",
        "        \"\"\"Generate unique ID for each skin rash image\"\"\"\n",
        "        return f\"rash_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "# --- 4. Fixed Medical Skin Rash Analyzer ---\n",
        "class MedicalSkinRashAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.model_name = None\n",
        "\n",
        "    def initialize_models(self):\n",
        "        \"\"\"Initialize AI models for skin rash analysis\"\"\"\n",
        "        try:\n",
        "            self.model_name = api_manager.get_best_model()\n",
        "            print(f\"ğŸ¤– Using model for skin rash analysis: {self.model_name}\")\n",
        "            print(\"âœ… Medical skin rash analyzer initialized successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Skin rash model initialization failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    def analyze_skin_rash(self, image_data: str) -> Generator[str, None, Dict]:\n",
        "        \"\"\"Comprehensive skin rash analysis with streaming details\"\"\"\n",
        "        print(\"ğŸ” Starting detailed skin rash analysis...\")\n",
        "\n",
        "        try:\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "            yield \"ğŸ”„ Initializing dermatological rash assessment...\\n\"\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            yield \"ğŸ“Š Analyzing rash morphology and distribution...\\n\"\n",
        "            time.sleep(0.7)\n",
        "\n",
        "            yield \"ğŸ¨ Examining color variations and inflammation patterns...\\n\"\n",
        "            time.sleep(0.6)\n",
        "\n",
        "            yield \"ğŸ”¬ Evaluating lesion types and skin surface changes...\\n\"\n",
        "            time.sleep(0.8)\n",
        "\n",
        "            yield \"ğŸ“ Measuring rash characteristics and patterns...\\n\"\n",
        "            time.sleep(1.0)\n",
        "\n",
        "            # Use direct generative AI for image analysis\n",
        "            vision_model = genai.GenerativeModel(self.model_name)\n",
        "\n",
        "            # Comprehensive rash analysis prompt\n",
        "            rash_analysis_prompt = \"\"\"\n",
        "            Analyze this skin image focusing EXCLUSIVELY on visible rash characteristics and dermatological manifestations.\n",
        "\n",
        "            Provide EXTREMELY DETAILED analysis covering:\n",
        "\n",
        "            RASH MORPHOLOGY DETAILS:\n",
        "            â€¢ Primary lesion types present (macules, papules, vesicles, pustules, plaques, nodules)\n",
        "            â€¢ Exact color characteristics and variations\n",
        "            â€¢ Surface texture and elevation details\n",
        "            â€¢ Border definition and regularity\n",
        "            â€¢ Distribution density and pattern\n",
        "\n",
        "            VISUAL CHARACTERISTICS INVENTORY:\n",
        "            â€¢ Size range of individual lesions\n",
        "            â€¢ Shape and configuration of rash elements\n",
        "            â€¢ Arrangement pattern (discrete, grouped, confluent, linear)\n",
        "            â€¢ Skin surface changes (scaling, crusting, erosion, lichenification)\n",
        "            â€¢ Presence of secondary features (exudate, hemorrhage, pigment changes)\n",
        "\n",
        "            INFLAMMATORY ASSESSMENT:\n",
        "            â€¢ Degree of erythema and vascular patterns\n",
        "            â€¢ Edema or swelling presence\n",
        "            â€¢ Signs of acute vs chronic inflammation\n",
        "            â€¢ Skin integrity assessment\n",
        "\n",
        "            RASH DISTRIBUTION ANALYSIS:\n",
        "            â€¢ Anatomical location specifics\n",
        "            â€¢ Symmetry or asymmetry\n",
        "            â€¢ Extent of involvement\n",
        "            â€¢ Pattern across skin surfaces\n",
        "\n",
        "            Provide purely descriptive analysis without diagnosis or database comparisons.\n",
        "            Focus only on what is visually apparent in the image.\n",
        "            Be exceptionally thorough and detailed in your visual observations.\n",
        "            \"\"\"\n",
        "\n",
        "            response = vision_model.generate_content([rash_analysis_prompt, image])\n",
        "\n",
        "            yield \"âœ… Detailed rash analysis complete! Compiling observations...\\n\"\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            final_analysis = {\n",
        "                \"raw_analysis\": response.text,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"status\": \"completed\",\n",
        "                \"model_used\": self.model_name,\n",
        "                \"analysis_type\": \"detailed_skin_rash_descriptive\"\n",
        "            }\n",
        "\n",
        "            yield final_analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"âŒ Rash analysis failure: {e}\\n\"\n",
        "            yield error_msg\n",
        "            # Provide a manual analysis fallback\n",
        "            fallback_analysis = \"\"\"\n",
        "            Based on visual inspection of the skin image, I can observe dermatological features that warrant detailed description:\n",
        "\n",
        "            VISUAL OBSERVATIONS:\n",
        "            â€¢ Various skin lesions and textural changes are present\n",
        "            â€¢ Color variations indicate potential inflammation or pigmentation changes\n",
        "            â€¢ The distribution pattern shows specific arrangement across the skin surface\n",
        "            â€¢ Surface characteristics suggest different types of skin manifestations\n",
        "\n",
        "            MORPHOLOGICAL FEATURES:\n",
        "            â€¢ Multiple lesion types may be present including possible papules or macules\n",
        "            â€¢ Border characteristics vary across different areas of involvement\n",
        "            â€¢ Texture changes indicate alterations in skin surface integrity\n",
        "\n",
        "            DISTRIBUTION PATTERNS:\n",
        "            â€¢ The rash appears in specific anatomical locations\n",
        "            â€¢ Pattern suggests either localized or widespread involvement\n",
        "            â€¢ Arrangement may indicate the nature of the dermatological process\n",
        "\n",
        "            Note: This is a general visual description. Professional medical evaluation is recommended for accurate assessment.\n",
        "            \"\"\"\n",
        "            fallback = {\n",
        "                \"raw_analysis\": fallback_analysis,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"status\": \"completed_fallback\",\n",
        "                \"model_used\": \"manual_observation\"\n",
        "            }\n",
        "            yield fallback\n",
        "\n",
        "    def extract_rash_findings(self, analysis_text: str) -> Dict:\n",
        "        \"\"\"Extract structured rash findings from detailed analysis\"\"\"\n",
        "        print(\"ğŸ“‹ Processing structured rash findings...\")\n",
        "\n",
        "        try:\n",
        "            # Use direct API call for reliability\n",
        "            model = genai.GenerativeModel(self.model_name)\n",
        "\n",
        "            extraction_prompt = f\"\"\"\n",
        "            Extract and structure the key rash observations from this detailed analysis:\n",
        "\n",
        "            DETAILED RASH ANALYSIS:\n",
        "            {analysis_text}\n",
        "\n",
        "            Structure the findings into these categories:\n",
        "\n",
        "            VISUAL MORPHOLOGY:\n",
        "            - Primary lesion types observed\n",
        "            - Color characteristics\n",
        "            - Surface texture details\n",
        "            - Border characteristics\n",
        "\n",
        "            DISTRIBUTION PATTERNS:\n",
        "            - Anatomical distribution\n",
        "            - Pattern arrangement\n",
        "            - Extent of involvement\n",
        "            - Symmetry assessment\n",
        "\n",
        "            INFLAMMATORY FEATURES:\n",
        "            - Erythema characteristics\n",
        "            - Edema presence\n",
        "            - Skin integrity status\n",
        "            - Surface changes\n",
        "\n",
        "            RASH CHARACTERISTICS SUMMARY:\n",
        "            - Overall rash description\n",
        "            - Key visual features\n",
        "            - Notable patterns\n",
        "            - Skin changes observed\n",
        "\n",
        "            Provide only structured observations from the analysis, no interpretations.\n",
        "            \"\"\"\n",
        "\n",
        "            response = model.generate_content(extraction_prompt)\n",
        "\n",
        "            # Parse structured findings\n",
        "            findings = {\n",
        "                \"visual_morphology\": [],\n",
        "                \"distribution_patterns\": [],\n",
        "                \"inflammatory_features\": [],\n",
        "                \"rash_characteristics\": [],\n",
        "                \"structured_summary\": response.text,\n",
        "                \"analysis_depth\": \"Detailed Visual\"\n",
        "            }\n",
        "\n",
        "            # Simple parsing\n",
        "            lines = response.text.split('\\n')\n",
        "            current_section = None\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if 'VISUAL MORPHOLOGY' in line.upper():\n",
        "                    current_section = 'visual_morphology'\n",
        "                elif 'DISTRIBUTION PATTERNS' in line.upper():\n",
        "                    current_section = 'distribution_patterns'\n",
        "                elif 'INFLAMMATORY FEATURES' in line.upper():\n",
        "                    current_section = 'inflammatory_features'\n",
        "                elif 'RASH CHARACTERISTICS' in line.upper():\n",
        "                    current_section = 'rash_characteristics'\n",
        "                elif line.startswith('-') and current_section and len(line) > 2:\n",
        "                    findings[current_section].append(line[1:].strip())\n",
        "\n",
        "            return findings\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Rash findings extraction error: {e}\")\n",
        "            return {\n",
        "                \"visual_morphology\": [\"Visible skin rash present with characteristic features\"],\n",
        "                \"distribution_patterns\": [\"Pattern analysis completed\"],\n",
        "                \"inflammatory_features\": [\"Inflammation characteristics documented\"],\n",
        "                \"rash_characteristics\": [\"Detailed rash observations recorded\"],\n",
        "                \"structured_summary\": \"Skin rash analysis completed with visual documentation.\",\n",
        "                \"analysis_depth\": \"Standard\"\n",
        "            }\n",
        "\n",
        "# --- 5. Skin Rash Chat Specialist ---\n",
        "class SkinRashChatSpecialist:\n",
        "    def __init__(self, analyzer: MedicalSkinRashAnalyzer):\n",
        "        self.analyzer = analyzer\n",
        "\n",
        "    def discuss_skin_rash(self, user_input: str, rash_analysis: Dict, rash_findings: Dict) -> str:\n",
        "        \"\"\"Discuss specific skin rash details\"\"\"\n",
        "        try:\n",
        "            # Use direct API call\n",
        "            model = genai.GenerativeModel(self.analyzer.model_name)\n",
        "\n",
        "            chat_prompt = f\"\"\"\n",
        "            You are a dermatology specialist discussing skin rash characteristics.\n",
        "\n",
        "            DETAILED RASH ANALYSIS OBSERVATIONS:\n",
        "            {rash_analysis.get('raw_analysis', 'Detailed rash analysis available')}\n",
        "\n",
        "            STRUCTURED FINDINGS:\n",
        "            {rash_findings.get('structured_summary', 'Structured rash findings')}\n",
        "\n",
        "            User's question: {user_input}\n",
        "\n",
        "            Respond with detailed descriptions of the visible rash characteristics.\n",
        "            Explain dermatological terms and provide educational information.\n",
        "            Always emphasize the need for professional medical evaluation.\n",
        "            Focus ONLY on describing what is visible.\n",
        "\n",
        "            Provide a helpful, detailed response:\n",
        "            \"\"\"\n",
        "\n",
        "            response = model.generate_content(chat_prompt)\n",
        "            return response.text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Rash discussion error: {e}\")\n",
        "            return f\"I can discuss the detailed characteristics of your skin rash. Based on the analysis, I observe various skin manifestations. What specific aspect of the rash would you like to know more about?\"\n",
        "\n",
        "    def generate_rash_summary(self, findings: Dict, image_id: str) -> str:\n",
        "        \"\"\"Generate comprehensive rash summary\"\"\"\n",
        "        try:\n",
        "            model = genai.GenerativeModel(self.analyzer.model_name)\n",
        "\n",
        "            summary_prompt = f\"\"\"\n",
        "            Create a comprehensive patient-friendly summary of this skin rash analysis:\n",
        "\n",
        "            RASH IMAGE ID: {image_id}\n",
        "\n",
        "            DETAILED RASH FINDINGS:\n",
        "            {findings.get('structured_summary', 'Rash analysis completed')}\n",
        "\n",
        "            Provide a clear summary covering:\n",
        "            1. Overall description of the visible rash\n",
        "            2. Key characteristics observed\n",
        "            3. Pattern and distribution notes\n",
        "            4. Visual features of interest\n",
        "            5. Recommended next steps for professional evaluation\n",
        "\n",
        "            Keep it descriptive and educational based only on visual observations.\n",
        "            \"\"\"\n",
        "\n",
        "            response = model.generate_content(summary_prompt)\n",
        "            return response.text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Rash summary error: {e}\")\n",
        "            return \"Skin rash analysis completed. The visual characteristics have been documented for professional review. Key observations include various lesion types and distribution patterns that should be evaluated by a dermatologist.\"\n",
        "\n",
        "# --- 6. Main Skin Rash Analysis Application ---\n",
        "def main():\n",
        "    print(\"\"\"\n",
        "    ğŸ¯ MEDICAL SKIN RASH ANALYSIS SYSTEM\n",
        "    ====================================\n",
        "    Exclusive Focus: Skin Rashes & Dermatological Manifestations\n",
        "    Features:\n",
        "    â€¢ Detailed visual rash analysis without database comparisons\n",
        "    â€¢ Streaming verbose observation reports\n",
        "    â€¢ Persistent conversation memory\n",
        "    â€¢ Interactive rash characteristic discussions\n",
        "    â€¢ Pure descriptive dermatological assessment\n",
        "    \"\"\")\n",
        "\n",
        "    # Initialize API\n",
        "    api_manager = APIKeyManager()\n",
        "    gemini_key = \"AIzaSyCR8xhkE6XNCdgmgRJFtKyodhsMz5jfbQE\"\n",
        "\n",
        "    if not gemini_key:\n",
        "        print(\"âŒ API key is required.\")\n",
        "        return\n",
        "\n",
        "    api_manager.set_gemini_key(gemini_key)\n",
        "\n",
        "    # Initialize skin rash components\n",
        "    image_processor = SkinRashImageProcessor()\n",
        "    rash_analyzer = MedicalSkinRashAnalyzer()\n",
        "\n",
        "    if not rash_analyzer.initialize_models():\n",
        "        print(\"âŒ Failed to initialize skin rash analysis models.\")\n",
        "        return\n",
        "\n",
        "    rash_chat = SkinRashChatSpecialist(rash_analyzer)\n",
        "    current_rash_analysis = None\n",
        "    current_rash_findings = None\n",
        "    current_rash_id = None\n",
        "\n",
        "    print(f\"\\nğŸŒŸ Skin Rash Analysis Specialist Ready!\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"ğŸ”„ SKIN RASH ANALYSIS MENU:\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"1. ğŸ“¤ Upload & Analyze Skin Rash Image\")\n",
        "        print(\"2. ğŸ’¬ Discuss Rash Characteristics\")\n",
        "        print(\"3. ğŸ“š View Rash Analysis History\")\n",
        "        print(\"4. ğŸ§  Show Conversation Memory\")\n",
        "        print(\"5. ğŸ—‘ï¸  Clear Current Session\")\n",
        "        print(\"6. ğŸšª Exit System\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        choice = input(\"\\nğŸ¯ Select option (1-6): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                print(\"\\nğŸ“¤ Please upload your skin rash image for detailed analysis...\")\n",
        "                uploaded = files.upload()\n",
        "\n",
        "                if not uploaded:\n",
        "                    print(\"âŒ No rash images uploaded\")\n",
        "                    continue\n",
        "\n",
        "                file_name = list(uploaded.keys())[0]\n",
        "                file_content = uploaded[file_name]\n",
        "\n",
        "                print(f\"âœ… Rash image '{file_name}' uploaded ({len(file_content)} bytes)\")\n",
        "\n",
        "                # Process image\n",
        "                print(\"\\nğŸ“¸ Optimizing image for rash analysis...\")\n",
        "                image_data = image_processor.prepare_image(file_content)\n",
        "\n",
        "                # Generate unique rash ID\n",
        "                current_rash_id = image_processor.generate_image_id()\n",
        "                print(f\"ğŸ†” Rash image ID: {current_rash_id}\")\n",
        "\n",
        "                # Streaming rash analysis\n",
        "                print(\"\\n\" + \"ğŸ”\" * 20)\n",
        "                print(\"STARTING DETAILED RASH ANALYSIS...\")\n",
        "                print(\"ğŸ”\" * 20 + \"\\n\")\n",
        "\n",
        "                analysis_result = None\n",
        "                for update in rash_analyzer.analyze_skin_rash(image_data):\n",
        "                    if isinstance(update, str):\n",
        "                        print(update, end='')\n",
        "                    else:\n",
        "                        analysis_result = update\n",
        "                        break\n",
        "\n",
        "                if analysis_result:\n",
        "                    print(\"\\nâœ… Rash analysis completed!\")\n",
        "\n",
        "                    # Extract structured rash findings\n",
        "                    print(\"\\nğŸ“‹ Processing rash characteristics...\")\n",
        "                    current_rash_findings = rash_analyzer.extract_rash_findings(analysis_result[\"raw_analysis\"])\n",
        "\n",
        "                    # Store in memory\n",
        "                    memory.store_image_analysis(current_rash_id, analysis_result, current_rash_findings)\n",
        "\n",
        "                    # Generate comprehensive summary\n",
        "                    summary = rash_chat.generate_rash_summary(current_rash_findings, current_rash_id)\n",
        "\n",
        "                    print(\"\\n\" + \"ğŸ“„\" * 20)\n",
        "                    print(\"DETAILED RASH ANALYSIS REPORT:\")\n",
        "                    print(\"ğŸ“„\" * 20)\n",
        "                    print(summary)\n",
        "                    print(\"ğŸ“„\" * 20)\n",
        "\n",
        "                    # Show key findings\n",
        "                    print(\"\\nğŸ”‘ KEY RASH CHARACTERISTICS IDENTIFIED:\")\n",
        "                    for category, items in current_rash_findings.items():\n",
        "                        if items and category != \"structured_summary\" and category != \"analysis_depth\":\n",
        "                            print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
        "                            for item in items[:3]:\n",
        "                                if item:  # Only print non-empty items\n",
        "                                    print(f\"  â€¢ {item}\")\n",
        "\n",
        "                    # Store initial conversation\n",
        "                    memory.add_exchange(\n",
        "                        user_input=f\"Uploaded skin rash image {current_rash_id} for analysis\",\n",
        "                        ai_response=summary,\n",
        "                        analysis_context=\"Initial detailed rash analysis\",\n",
        "                        image_data={\"rash_id\": current_rash_id, \"type\": \"rash_analysis\"}\n",
        "                    )\n",
        "\n",
        "                    current_rash_analysis = analysis_result\n",
        "\n",
        "                    print(f\"\\nğŸ’¬ You can now discuss specific rash characteristics using option 2!\")\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"âŒ Colab environment required for file uploads\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Rash analysis error: {e}\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            if not current_rash_analysis:\n",
        "                print(\"âŒ Please upload and analyze a skin rash image first (Option 1)\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nğŸ’¬ RASH DISCUSSION: Image {current_rash_id}\")\n",
        "            print(\"Ask specific questions about:\")\n",
        "            print(\"â€¢ Rash morphology and characteristics\")\n",
        "            print(\"â€¢ Color patterns and inflammation\")\n",
        "            print(\"â€¢ Distribution and arrangement\")\n",
        "            print(\"â€¢ Dermatological terminology explanations\")\n",
        "            print(\"Type 'back' to return to main menu.\\n\")\n",
        "\n",
        "            while True:\n",
        "                user_input = input(\"ğŸ‘¤ You: \").strip()\n",
        "\n",
        "                if user_input.lower() in ['back', 'exit', 'quit']:\n",
        "                    print(\"â†©ï¸ Returning to main menu...\")\n",
        "                    break\n",
        "\n",
        "                if not user_input:\n",
        "                    continue\n",
        "\n",
        "                # Generate detailed rash discussion\n",
        "                response = rash_chat.discuss_skin_rash(\n",
        "                    user_input,\n",
        "                    current_rash_analysis,\n",
        "                    current_rash_findings\n",
        "                )\n",
        "\n",
        "                print(f\"\\nğŸ¤– Rash Specialist: {response}\\n\")\n",
        "\n",
        "                # Store in memory with rash reference\n",
        "                memory.add_exchange(\n",
        "                    user_input=user_input,\n",
        "                    ai_response=response,\n",
        "                    analysis_context=f\"Rash characteristic discussion: {current_rash_id}\",\n",
        "                    image_data={\"rash_id\": current_rash_id, \"topic\": user_input[:50]}\n",
        "                )\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"\\nğŸ“š RASH ANALYSIS HISTORY:\")\n",
        "            images = memory.get_image_references()\n",
        "\n",
        "            if not images:\n",
        "                print(\"No previous rash analyses stored.\")\n",
        "            else:\n",
        "                for img in images:\n",
        "                    print(f\"\\nğŸ–¼ï¸ Rash ID: {img['id']}\")\n",
        "                    print(f\"ğŸ“… Analyzed: {img['timestamp'][:10]} {img['timestamp'][11:19]}\")\n",
        "                    print(f\"ğŸ” Analysis Depth: {img.get('findings', {}).get('analysis_depth', 'Unknown')}\")\n",
        "                    findings = img.get('findings', {})\n",
        "                    if 'visual_morphology' in findings and findings['visual_morphology']:\n",
        "                        print(f\"ğŸ‘ï¸ Key Feature: {findings['visual_morphology'][0][:50]}...\")\n",
        "                    print(\"-\" * 40)\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"\\nğŸ§  RASH CONVERSATION MEMORY:\")\n",
        "            print(memory.get_recent_context())\n",
        "            print(f\"\\nğŸ“Š Session Statistics:\")\n",
        "            print(f\"â€¢ Total Rash Discussions: {len(memory.history)}\")\n",
        "            print(f\"â€¢ Analyzed Rash Images: {len(memory.uploaded_images)}\")\n",
        "            print(f\"â€¢ Current Session: {len(memory.current_session)} exchanges\")\n",
        "\n",
        "        elif choice == '5':\n",
        "            memory.clear_current_session()\n",
        "            current_rash_analysis = None\n",
        "            current_rash_findings = None\n",
        "            print(\"ğŸ”„ Current rash session cleared. Historical analyses preserved.\")\n",
        "\n",
        "        elif choice == '6':\n",
        "            print(\"\\nğŸ‘‹ Thank you for using the Medical Skin Rash Analysis System!\")\n",
        "            print(\"ğŸ’¾ Your detailed rash analyses and discussions have been saved.\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"âŒ Please select a valid option (1-6)\")\n",
        "\n",
        "# Quick start with error handling\n",
        "def quick_start():\n",
        "    \"\"\"Quick start the skin rash analysis system\"\"\"\n",
        "    print(\"ğŸš€ Starting Medical Skin Rash Analysis System...\")\n",
        "\n",
        "    api_manager = APIKeyManager()\n",
        "    api_key = \"AIzaSyCR8xhkE6XNCdgmgRJFtKyodhsMz5jfbQE\"\n",
        "\n",
        "    try:\n",
        "        api_manager.set_gemini_key(api_key)\n",
        "        analyzer = MedicalSkinRashAnalyzer()\n",
        "        if analyzer.initialize_models():\n",
        "            print(f\"âœ… Skin Rash Analysis System Ready!\")\n",
        "            return analyzer\n",
        "        else:\n",
        "            print(\"âŒ System initialization failed\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Startup error: {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Start the system\n",
        "    system = quick_start()\n",
        "    if system:\n",
        "        print(\"\\nğŸ¯ Medical Skin Rash Analysis System is fully operational!\")\n",
        "        print(\"Exclusive focus on skin rash characteristics and dermatological observations.\")\n",
        "        print(\"No database comparisons - pure descriptive analysis only.\")\n",
        "\n",
        "        # Start the main application\n",
        "        main()\n",
        "    else:\n",
        "        print(\"âŒ Failed to start the system. Please check your API key and try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QMw0vnTCQV92",
        "outputId": "99dc07d4-8caa-4660-c7ac-50d8c03a8d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ’¾ Skin rash memory system initialized\n",
            "ğŸš€ Starting Medical Skin Rash Analysis System...\n",
            "ğŸ”‘ API configuration completed successfully\n",
            "ğŸ“‹ Available models: gemini-2.5-pro-preview-03-25, gemini-2.5-flash-preview-05-20, gemini-2.5-flash, gemini-2.5-flash-lite-preview-06-17, gemini-2.5-pro-preview-05-06, gemini-2.5-pro-preview-06-05, gemini-2.5-pro, gemini-2.0-flash-exp, gemini-2.0-flash, gemini-2.0-flash-001, gemini-2.0-flash-exp-image-generation, gemini-2.0-flash-lite-001, gemini-2.0-flash-lite, gemini-2.0-flash-preview-image-generation, gemini-2.0-flash-lite-preview-02-05, gemini-2.0-flash-lite-preview, gemini-2.0-pro-exp, gemini-2.0-pro-exp-02-05, gemini-exp-1206, gemini-2.0-flash-thinking-exp-01-21, gemini-2.0-flash-thinking-exp, gemini-2.0-flash-thinking-exp-1219, gemini-2.5-flash-preview-tts, gemini-2.5-pro-preview-tts, learnlm-2.0-flash-experimental, gemma-3-1b-it, gemma-3-4b-it, gemma-3-12b-it, gemma-3-27b-it, gemma-3n-e4b-it, gemma-3n-e2b-it, gemini-flash-latest, gemini-flash-lite-latest, gemini-pro-latest, gemini-2.5-flash-lite, gemini-2.5-flash-image-preview, gemini-2.5-flash-image, gemini-2.5-flash-preview-09-2025, gemini-2.5-flash-lite-preview-09-2025, gemini-robotics-er-1.5-preview\n",
            "âœ… Using preferred models: gemini-2.5-flash-preview-05-20, gemini-2.5-flash, gemini-2.5-pro-preview-03-25, gemini-2.0-flash\n",
            "ğŸ¤– Using model for skin rash analysis: gemini-2.5-flash\n",
            "âœ… Medical skin rash analyzer initialized successfully\n",
            "âœ… Skin Rash Analysis System Ready!\n",
            "\n",
            "ğŸ¯ Medical Skin Rash Analysis System is fully operational!\n",
            "Exclusive focus on skin rash characteristics and dermatological observations.\n",
            "No database comparisons - pure descriptive analysis only.\n",
            "\n",
            "    ğŸ¯ MEDICAL SKIN RASH ANALYSIS SYSTEM\n",
            "    ====================================\n",
            "    Exclusive Focus: Skin Rashes & Dermatological Manifestations\n",
            "    Features:\n",
            "    â€¢ Detailed visual rash analysis without database comparisons\n",
            "    â€¢ Streaming verbose observation reports\n",
            "    â€¢ Persistent conversation memory\n",
            "    â€¢ Interactive rash characteristic discussions\n",
            "    â€¢ Pure descriptive dermatological assessment\n",
            "    \n",
            "ğŸ”‘ API configuration completed successfully\n",
            "ğŸ“‹ Available models: gemini-2.5-pro-preview-03-25, gemini-2.5-flash-preview-05-20, gemini-2.5-flash, gemini-2.5-flash-lite-preview-06-17, gemini-2.5-pro-preview-05-06, gemini-2.5-pro-preview-06-05, gemini-2.5-pro, gemini-2.0-flash-exp, gemini-2.0-flash, gemini-2.0-flash-001, gemini-2.0-flash-exp-image-generation, gemini-2.0-flash-lite-001, gemini-2.0-flash-lite, gemini-2.0-flash-preview-image-generation, gemini-2.0-flash-lite-preview-02-05, gemini-2.0-flash-lite-preview, gemini-2.0-pro-exp, gemini-2.0-pro-exp-02-05, gemini-exp-1206, gemini-2.0-flash-thinking-exp-01-21, gemini-2.0-flash-thinking-exp, gemini-2.0-flash-thinking-exp-1219, gemini-2.5-flash-preview-tts, gemini-2.5-pro-preview-tts, learnlm-2.0-flash-experimental, gemma-3-1b-it, gemma-3-4b-it, gemma-3-12b-it, gemma-3-27b-it, gemma-3n-e4b-it, gemma-3n-e2b-it, gemini-flash-latest, gemini-flash-lite-latest, gemini-pro-latest, gemini-2.5-flash-lite, gemini-2.5-flash-image-preview, gemini-2.5-flash-image, gemini-2.5-flash-preview-09-2025, gemini-2.5-flash-lite-preview-09-2025, gemini-robotics-er-1.5-preview\n",
            "âœ… Using preferred models: gemini-2.5-flash-preview-05-20, gemini-2.5-flash, gemini-2.5-pro-preview-03-25, gemini-2.0-flash\n",
            "ğŸ¤– Using model for skin rash analysis: gemini-2.5-flash\n",
            "âœ… Medical skin rash analyzer initialized successfully\n",
            "\n",
            "ğŸŒŸ Skin Rash Analysis Specialist Ready!\n",
            "\n",
            "==================================================\n",
            "ğŸ”„ SKIN RASH ANALYSIS MENU:\n",
            "==================================================\n",
            "1. ğŸ“¤ Upload & Analyze Skin Rash Image\n",
            "2. ğŸ’¬ Discuss Rash Characteristics\n",
            "3. ğŸ“š View Rash Analysis History\n",
            "4. ğŸ§  Show Conversation Memory\n",
            "5. ğŸ—‘ï¸  Clear Current Session\n",
            "6. ğŸšª Exit System\n",
            "==================================================\n",
            "\n",
            "ğŸ“¤ Please upload your skin rash image for detailed analysis...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-afce7a9e-d208-4000-83c1-e79288254e3f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-afce7a9e-d208-4000-83c1-e79288254e3f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving image3-1.jpg to image3-1.jpg\n",
            "âœ… Rash image 'image3-1.jpg' uploaded (102430 bytes)\n",
            "\n",
            "ğŸ“¸ Optimizing image for rash analysis...\n",
            "ğŸ“Š Processing skin rash image: 102430 bytes\n",
            "ğŸ“ Original dimensions: (800, 600)\n",
            "ğŸ“ Optimized for rash analysis: (512, 384)\n",
            "âœ… Skin rash image ready for analysis: 53908 bytes\n",
            "ğŸ†” Rash image ID: rash_20251007_155348\n",
            "\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "STARTING DETAILED RASH ANALYSIS...\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "\n",
            "ğŸ” Starting detailed skin rash analysis...\n",
            "ğŸ”„ Initializing dermatological rash assessment...\n",
            "ğŸ“Š Analyzing rash morphology and distribution...\n",
            "ğŸ¨ Examining color variations and inflammation patterns...\n",
            "ğŸ”¬ Evaluating lesion types and skin surface changes...\n",
            "ğŸ“ Measuring rash characteristics and patterns...\n",
            "âœ… Detailed rash analysis complete! Compiling observations...\n",
            "\n",
            "âœ… Rash analysis completed!\n",
            "\n",
            "ğŸ“‹ Processing rash characteristics...\n",
            "ğŸ“‹ Processing structured rash findings...\n",
            "ğŸ–¼ï¸ Skin rash analysis stored: rash_20251007_155348\n",
            "\n",
            "ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„\n",
            "DETAILED RASH ANALYSIS REPORT:\n",
            "ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„\n",
            "Based on a visual analysis of the skin rash images, here's a patient-friendly summary:\n",
            "\n",
            "---\n",
            "\n",
            "### Patient-Friendly Summary of Your Skin Rash Analysis\n",
            "\n",
            "**1. Overall Description of the Visible Rash:**\n",
            "You have a noticeably red and inflamed skin rash, primarily located on the left side of your face, covering a significant portion of your left cheek. It appears to be an acute (meaning it likely developed recently or suddenly) and inflammatory rash, suggesting your body is reacting strongly to something.\n",
            "\n",
            "**2. Key Characteristics Observed:**\n",
            "*   **Bumps and Spots:** The rash is made up of many small, raised red bumps. Mixed in with these are numerous \"pus-filled spots\" (pustules), which are essentially bumps with distinct yellowish-white centers indicating a collection of pus.\n",
            "*   **Redness:** The skin around and under these bumps is quite red, ranging from a moderate pinkish-red to a very bright, intense scarlet-red in the most affected areas.\n",
            "*   **Swelling:** There's significant swelling and puffiness in the affected area of your cheek, making the skin appear raised and thickened, especially where the rash is most dense.\n",
            "*   **Surface:** The bumps and pus-filled spots generally have a smooth, somewhat taut surface. The surrounding skin also appears smooth, with no obvious flaking, peeling, or open sores. The pus is contained within the spots and is not oozing out.\n",
            "\n",
            "**3. Pattern and Distribution Notes:**\n",
            "*   **Location:** The rash is very prominent on your left cheek, extending towards the eye area, side of the nose, and down across the middle of the cheek.\n",
            "*   **Spread:** It's concentrated heavily in the central part of your left cheek, where the individual spots are very close together and appear to merge into larger patches of intense redness and inflammation. Towards the edges of the rash, the spots become more scattered and distinct.\n",
            "*   **Asymmetry:** This rash is clearly more severe and noticeable on the left side of your face, showing a marked difference compared to the right side.\n",
            "\n",
            "**4. Visual Features of Interest:**\n",
            "The most striking features are the combination of the bright, vivid red color, the noticeable raised bumps and yellow-centered pus spots, and the visible swelling that changes the contour of your cheek. Despite the inflammation, the skin surface largely remains intact, with no signs of scaling, crusting (dried scabs), or large areas of skin breakdown.\n",
            "\n",
            "**5. Recommended Next Steps for Professional Evaluation:**\n",
            "Based purely on these visual observations, it is **highly recommended that you see a doctor or dermatologist as soon as possible.** While this analysis describes what is visible, it cannot provide a diagnosis or recommend specific treatment. A healthcare professional will be able to:\n",
            "*   Perform a physical examination.\n",
            "*   Ask you questions about your medical history and symptoms (e.g., pain, itching, fever).\n",
            "*   Potentially run tests (like a skin culture) to determine the exact cause of the rash.\n",
            "*   Provide an accurate diagnosis and an appropriate treatment plan to help clear up the rash and manage any discomfort.\n",
            "ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„ğŸ“„\n",
            "\n",
            "ğŸ”‘ KEY RASH CHARACTERISTICS IDENTIFIED:\n",
            "ğŸ’¾ Memory updated: 1 total exchanges\n",
            "\n",
            "ğŸ’¬ You can now discuss specific rash characteristics using option 2!\n",
            "\n",
            "==================================================\n",
            "ğŸ”„ SKIN RASH ANALYSIS MENU:\n",
            "==================================================\n",
            "1. ğŸ“¤ Upload & Analyze Skin Rash Image\n",
            "2. ğŸ’¬ Discuss Rash Characteristics\n",
            "3. ğŸ“š View Rash Analysis History\n",
            "4. ğŸ§  Show Conversation Memory\n",
            "5. ğŸ—‘ï¸  Clear Current Session\n",
            "6. ğŸšª Exit System\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}